{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interactive, widgets\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "from matplotlib.widgets import PolygonSelector\n",
    "from matplotlib.patches import Ellipse\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
    "import json\n",
    "import textwrap\n",
    "import ast\n",
    "import pickle as pkl\n",
    "\n",
    "from camera import Camera\n",
    "from dorna2 import Dorna\n",
    "\n",
    "#from dorna_vision.draw import *\n",
    "from detect import *\n",
    "from draw import *\n",
    "from util import *\n",
    "\n",
    "\n",
    "\n",
    "class default_widget(object):\n",
    "    \"\"\"docstring for ClassName\"\"\"\n",
    "    def __init__(self,):\n",
    "        super(default_widget, self).__init__()\n",
    "        continuous_update = False\n",
    "        style={'description_width': '150px'}\n",
    "        widgets.IntText(value=7, description='Any:', disabled=False)\n",
    "        self.widget_helper = {\n",
    "            \"xyz_label\": widgets.HTML(value=\"Convert pixel coordinates to its 3D spatial values based on the predefined reference frame.\", layout={'width': '99%'}, style=style),\n",
    "            \"xyz_width\": widgets.IntText(value=10, placeholder=10, description='Width (pxl)', disabled=False, style=style),\n",
    "            \"xyz_height\": widgets.IntText(value=10, placeholder=10, description='Height (pxl)', disabled=False, style=style),\n",
    "            \"xyz_xyz\": widgets.Text(value='[0, 0, 0]', placeholder='[0, 0, 0]', description='Result (mm)', disabled=True, style=style),\n",
    "            \"xyz_convert\": widgets.Button( description='Convert', disabled=False, button_style=\"\", tooltip='Convert'),\n",
    "        }\n",
    "\n",
    "        self.widget_init = {\n",
    "            \"camera_setup_label\": widgets.HTML(value=\"<ul><li><strong>Eye-in-hand</strong>: When the camera is mounted on the robot, input the robot's IP address to synchronize the 3D data with the robot.</li><li><strong>Eye-to-hand</strong>: If the camera is stationary, leave the robot's IP address field blank.</li></ul>\", layout={'width': '99%'}, style=style),\n",
    "            \"camera_setup_type\": widgets.Dropdown(value=0, options=[('Eye-in-hand', 0), ('Eye-to-hand', 1),], description='Mounting setup', continuous_update=continuous_update, style=style),\n",
    "            \"camera_setup_robot_ip\": widgets.Text(value='localhost', placeholder='localhost', description='Robot IP address', disabled=False, style=style),\n",
    "            \"frame_label\": widgets.HTML(value=\"Specify the reference frame based on the camera's setup:    <ul> <li>If the camera is attached to the robot (eye-in-hand), set it relative to the robot's base frame.</li> <li>If the camera is fixed (eye-to-hand), set it relative to the camera frame.</li> </ul> All measurements will be reported concerning this selected frame.\", layout={'width': '99%'}, style=style),\n",
    "            \"frame_value\": widgets.Text(value='[0, 0, 0, 0, 0, 0]', placeholder='[0, 0, 0, 0, 0, 0]', description='Frame', disabled=False, style=style),\n",
    "            \"ml_label\": widgets.HTML(value=\"Specify the path to the model, for any ML-based detection method.\", layout={'width': '99%'}, style=style),\n",
    "            \"ml_detection_type\": widgets.Dropdown(value=0, options=[('Object detection', 0), ('Image classification', 1)], description='Detection method', continuous_update=continuous_update, style=style),\n",
    "            \"ml_detection_path\": widgets.Text(value='', placeholder='Path to the detection model file (*.pkl), e.g., ai_models/test.pkl.', description='Model path', disabled=False, layout={'width': '99%'}, style=style),\n",
    "\n",
    "            \"init\": widgets.Button( description='Initialize Parameters', disabled=False, tooltip='Initialize Parameters', button_style=\"success\"), \n",
    "        }\n",
    "        self.widget_input = {\n",
    "            \"plane_label\": widgets.Label(value=\"Select 3 points relative to the oriented bounding box to define a hyperplane and determine the 6D pose of the detected item.\", layout={'width': '99%'}, style=style),\n",
    "            \"plane_enb\": widgets.Checkbox(value=False, description='Apply the 6D-pose', continuous_update=continuous_update, layout={'width': '99%'}, style=style),\n",
    "            \"plane_value\": widgets.Text(value=\"[]\", placeholder='[]', description='Plane', disabled=True, layout={'width': '99%'}, style=style),\n",
    "            \n",
    "            \"color_label\": widgets.Label(value=\"Apply a color mask to filter specific colors by adjusting hue, saturation, and value. Fine-tune these settings to isolate the desired color range for better detection results.\", layout={'width': '99%'}, style=style),\n",
    "            \"color_enb\": widgets.Checkbox(value=False, description='Enable color mask', continuous_update=continuous_update, layout={'width': '99%'}, style=style),\n",
    "            \"color_h\": widgets.IntRangeSlider(value=[60, 120], min=0, max=179, step=1, description='Hue', continuous_update=continuous_update, layout={'width': '99%'}, style=style),\n",
    "            \"color_s\": widgets.IntRangeSlider(value=[85, 170], min=0, max=255, step=1, description='Saturation', continuous_update=continuous_update, layout={'width': '99%'}, style=style),\n",
    "            \"color_v\": widgets.IntRangeSlider(value=[85, 170], min=0, max=255, step=1, description='Vue', continuous_update=continuous_update, layout={'width': '99%'}, style=style),\n",
    "            \"color_inv\": widgets.Checkbox(value=False, description='Invert color mask', continuous_update=continuous_update, layout={'width': '99%'}, style=style),\n",
    "\n",
    "            \"roi_label\": widgets.Label(value=\"Select the region of interest where the detection method is applied. Use the blue polygon selector on the output image to define this area.\", layout={'width': '99%'}, style=style),\n",
    "            \"roi_enb\": widgets.Checkbox(value=False, description='Enable ROI', continuous_update=continuous_update, layout={'width': '99%'}, style=style),\n",
    "            \"roi_value\": widgets.Text(value='[]', placeholder='[]', description='ROI', disabled=True, layout={'width': '99%'}, style=style),\n",
    "            \"roi_inv\": widgets.Checkbox(value=False, description='Invert region', continuous_update=continuous_update, layout={'width': '99%'}, style=style),\n",
    "            \"roi_crop\": widgets.Checkbox(value=False, description='Crop region', continuous_update=continuous_update, layout={'width': '99%'}, style=style),\n",
    "\n",
    "            \"intensity_label\": widgets.Label(value=\"Adjust brightness and contrast if necessary to enhance image details. Use the sliders for optimal visibility and improved detection results.\", layout={'width': '99%'}, style=style),\n",
    "            \"intensity_enb\": widgets.Checkbox(value=False, description='Apply the intensity', continuous_update=continuous_update, layout={'width': '99%'}, style=style),\n",
    "            \"intensity_a\" : widgets.FloatSlider(value=1, min=0, max=4, step=0.01, description='Contrast', continuous_update=continuous_update, layout={'width': '99%'}, style=style),\n",
    "            \"intensity_b\" : widgets.IntSlider(value=0, min=-255, max=255, step=1, description='Brightness', continuous_update=continuous_update, layout={'width': '99%'}, style=style),\n",
    "\n",
    "            \"2d_range_label\": widgets.Label(value=\"Apply 2D constraints on the detected item's oriented bounding box aspect ratio and area to refine detection accuracy.\", layout={'width': '99%'}, style=style),\n",
    "            \"2d_range_enb\": widgets.Checkbox(value=False, description='Apply the size constraints', continuous_update=continuous_update,layout={'width': '99%'}, style=style),\n",
    "            \"2d_range_aspect_ratio\": widgets.FloatRangeSlider(value=[0, 1], min=0, max=1, step=0.01, description='Aspect ratio', continuous_update=continuous_update, layout={'width': '99%'}, style=style),\n",
    "            \"2d_range_area_range\": widgets.IntRangeSlider(value=[0, 100000], min=0, max=100000, step=100, description='Area (pxl X pxl)', continuous_update=continuous_update, layout={'width': '99%'}, style=style),\n",
    "\n",
    "            \"3d_range_label\": widgets.Label(value=\"Apply 3D constraints to remove detected items outside the specified x, y, z range relative to the frame.\", layout={'width': '99%'}, style=style),\n",
    "            \"3d_range_enb\": widgets.Checkbox(value=False, description='Apply the spatial constraints', continuous_update=continuous_update, layout={'width': '99%'}, style=style),\n",
    "            \"3d_range_x\": widgets.IntRangeSlider(value=[250, 350], min=-1000, max=1000, step=1, description='x (mm)', continuous_update=continuous_update, layout={'width': '99%'}, style=style),\n",
    "            \"3d_range_y\": widgets.IntRangeSlider(value=[0, 50], min=-1000, max=1000, step=1, description='y (mm)', continuous_update=continuous_update, layout={'width': '99%'}, style=style),\n",
    "            \"3d_range_z\": widgets.IntRangeSlider(value=[0, 50], min=-1000, max=1000, step=1, description='z (mm)', continuous_update=continuous_update, layout={'width': '99%'}, style=style),\n",
    "            \"3d_range_inv\": widgets.Checkbox(value=False, description='Invert the range', continuous_update=continuous_update, layout={'width': '99%'}, style=style),\n",
    "\n",
    "            \"method_value\": widgets.Dropdown(value=0, options=[('No detection', 0), ('Ellipse detection', 1), ('Polygon detection', 2), ('Contour detection', 3), ('Aruco detection', 4), ('OCR detection', 5)], description='Detection method', continuous_update=continuous_update, style=style),\n",
    "    \n",
    "            \"m_elp_pf_mode\": widgets.Checkbox(value=False, description='Auto detection', continuous_update=continuous_update,layout={'width': '99%'}, style=style),\n",
    "            \"m_elp_nfa_validation\": widgets.Checkbox(value=True, description='False alarm validation', continuous_update=continuous_update, layout={'width': '99%'}, style=style),\n",
    "            \"m_elp_min_path_length\": widgets.IntSlider(value=50, min=1, max=1000, step=1, description='Min path length', continuous_update=continuous_update, layout={'width': '99%'}, style=style),\n",
    "            \"m_elp_min_line_length\": widgets.IntSlider(value=10, min=1, max=1000, step=1, description='Min line length', continuous_update=continuous_update, layout={'width': '99%'}, style=style),\n",
    "            \"m_elp_sigma\": widgets.IntSlider(value=1, min=0, max=20, step=0.1, description='Blur', continuous_update=continuous_update, layout={'width': '99%'}, style=style),\n",
    "            \"m_elp_gradient_threshold_value\": widgets.IntSlider(value=20, min=1, max=100, step=1, description='Gradient', continuous_update=continuous_update, layout={'width': '99%'}, style=style),\n",
    "    \n",
    "\n",
    "            \"m_poly_inv\": widgets.Checkbox(value=True, description='Inverse', continuous_update=continuous_update, layout={'width': '99%'}, style=style),\n",
    "            \"m_poly_type\": widgets.Dropdown(value=0, options=[('0: Otsu (auto)', 0), ('1: Binary', 1), ('2: Gaussian', 2)], description='Type', continuous_update=continuous_update, layout={'width': '99%'}, style=style),\n",
    "            \"m_poly_thr\" : widgets.IntSlider(value=127, min=0, max=255, step=1, description='Threshold value', continuous_update=continuous_update, layout={'width': '99%'}, style=style),\n",
    "            \"m_poly_blur\": widgets.IntSlider(value=3, min=1, max=20, step=1, description='Smoothing blur', continuous_update=continuous_update, layout={'width': '99%'}, style=style),                    \n",
    "            \"m_poly_mean_sub\": widgets.IntSlider(value=0, min=-200, max=200, step=1, description='Mean subtract', continuous_update=continuous_update, layout={'width': '99%'}, style=style),\n",
    "            \"m_poly_side\" : widgets.IntSlider(value=3, min=3, max=20, step=1, description='Sides', continuous_update=continuous_update, layout={'width': '99%'}, style=style),\n",
    "\n",
    "            \n",
    "            \"m_cnt_inv\": widgets.Checkbox(value=True, description='Inverse', continuous_update=continuous_update, layout={'width': '99%'}, style=style),\n",
    "            \"m_cnt_type\": widgets.Dropdown(value=0, options=[('0: Otsu (auto)', 0), ('1: Binary', 1), ('2: Gaussian', 2)], description='Type', continuous_update=continuous_update, layout={'width': '99%'}, style=style),\n",
    "            \"m_cnt_thr\" : widgets.IntSlider(value=127, min=0, max=255, step=1, description='Threshold value', continuous_update=continuous_update, layout={'width': '99%'}, style=style),\n",
    "            \"m_cnt_blur\": widgets.IntSlider(value=3, min=1, max=20, step=1, description='Smoothing blur', continuous_update=continuous_update, layout={'width': '99%'}, style=style),                    \n",
    "            \"m_cnt_mean_sub\": widgets.IntSlider(value=0, min=-200, max=200, step=1, description='Mean subtract', continuous_update=continuous_update, layout={'width': '99%'}, style=style),\n",
    "\n",
    "            \"m_aruco_dictionary\":widgets.Dropdown(value=\"DICT_6X6_250\", options= [\"DICT_4X4_50\", \"DICT_4X4_100\", \"DICT_4X4_250\", \"DICT_4X4_1000\", \"DICT_5X5_50\", \"DICT_5X5_100\", \"DICT_5X5_250\", \"DICT_5X5_1000\", \"DICT_6X6_50\", \"DICT_6X6_100\", \"DICT_6X6_250\", \"DICT_6X6_1000\", \"DICT_7X7_50\", \"DICT_7X7_100\", \"DICT_7X7_250\", \"DICT_7X7_1000\", \"DICT_ARUCO_ORIGINAL\", \"DICT_APRILTAG_16h5\", \"DICT_APRILTAG_25h9\", \"DICT_APRILTAG_36h10\", \"DICT_APRILTAG_36h11\"], description='Dictionary', continuous_update=continuous_update, layout={'width': '99%'}, style=style),\n",
    "            \"m_aruco_marker_length\": widgets.FloatSlider(value=10, min=1, max=100, step=0.1, description='Marker length (mm)', continuous_update=continuous_update, layout={'width': '99%'}, style=style),\n",
    "            \"m_aruco_refine\":widgets.Dropdown(value=\"CORNER_REFINE_APRILTAG\", options=[\"CORNER_REFINE_NONE\", \"CORNER_REFINE_SUBPIX\", \"CORNER_REFINE_CONTOUR\", \"CORNER_REFINE_APRILTAG\"], description='Refinement', continuous_update=continuous_update, layout={'width': '99%'}, style=style),\n",
    "            \"m_aruco_subpix\": widgets.Checkbox(value=False, description='Sub pixel', continuous_update=continuous_update, layout={'width': '99%'}, style=style),            \n",
    "\n",
    "            \"m_ocr_conf\" : widgets.FloatSlider(value=0.5, min=0.01, max=1, step=0.01, description='Confidence', continuous_update=continuous_update, layout={'width': '99%'}, style=style), \n",
    "\n",
    "            \"m_od_conf\" : widgets.FloatSlider(value=0.5, min=0.01, max=1, step=0.01, description='Confidence', continuous_update=continuous_update, layout={'width': '99%'}, style=style), \n",
    "            \"m_od_cls\" : widgets.Text(value=\"\", placeholder='', description='Detection classes', disabled=False, layout={'width': '99%'}, style=style), \n",
    "\n",
    "            \"m_cls_conf\" : widgets.FloatSlider(value=0.5, min=0.01, max=1, step=0.01, description='Confidence', continuous_update=continuous_update, layout={'width': '99%'}, style=style), \n",
    "\n",
    "            #\"output_label\": widgets.Label(value=\"Select the maximum number of elements to be detected in each inference round.\", layout={'width': '99%'}, style=style),\n",
    "            \"output_max_det\" : widgets.IntSlider(value=10, min=1, max=100, step=1, description='Max detections per run', continuous_update=continuous_update, layout={'width': '99%'}, style=style), \n",
    "            \"output_shuffle\": widgets.Checkbox(value=True, description='Shuffle return data', continuous_update=continuous_update, layout={'width': '99%'}, style=style),\n",
    "            \"output_save\": widgets.Checkbox(value=False, description='Save the annotated image in the \"output/*.jpg\"', continuous_update=continuous_update, layout={'width': '99%'}, style=style),\n",
    "        }\n",
    "        self.widget_trigger = {\n",
    "            \"color_picker\": widgets.ColorPicker(concise=False, description='Color picker', value='blue', disabled=False, style={'text_width': '0'}),\n",
    "            \"color_hsv\": widgets.Text(value='Hue = 119, Saturation = 255, Value = 255', placeholder='', description='', disabled=True,),            \n",
    "\n",
    "            \"source_value\": widgets.Dropdown(value=0, options=[('Stereo camera', 0), ('File', 1)], description='Image source', continuous_update=continuous_update, style=style),\n",
    "            \"source_feed\": widgets.Dropdown(value=\"color_img\", options=[('Color image', \"color_img\")], description='Feed', continuous_update=continuous_update, style=style, layout={'visible': 'none'}),\n",
    "\n",
    "            \"s_file_value\": widgets.Text(value='', placeholder='Path to the file (*.jpg, *.jpeg, *.png, *.tiff, ...).Ex: img/test.jpg', description='File path', disabled=False, layout={'width': '99%'}, style=style),            \n",
    "            \"s_apply\": widgets.Button( description='Capture Image', disabled=True, button_style=\"success\", tooltip='Capture Image', style=style),\n",
    "            #\"s_update\": widgets.Button( description='', disabled=False, button_style=\"\", tooltip='Update source list', icon='refresh', layout={'width': '50px'}),\n",
    "            \"s_save_path\": widgets.Text(value='', placeholder='*.jpg', description='Save image as', disabled=False, layout={'width': '99%'}),            \n",
    "            \"s_save\": widgets.Button( description='Save', disabled=False, button_style=\"\", tooltip='Save as'),\n",
    "\n",
    "            #\"model_path\": widgets.Text(value='', placeholder='/full_path/to_the/object_detection_model.pkl', description='Object Detection Model', disabled=False, layout={'width': '99%'}, style=style),            \n",
    "            #\"model_save\": widgets.Button( description='Set', disabled=False, button_style=\"\", tooltip='Set'),\n",
    "\n",
    "            #\"robot_ip\": widgets.Text(value='', placeholder='192.168.254.10', description='Robot IP Address', disabled=False, layout={'width': '99%'}, style=style),            \n",
    "            #\"robot_connect\": widgets.Button( description='Connect', disabled=False, button_style=\"\", tooltip='Connect'),\n",
    "\n",
    "            #\"camera_robot_calibration\": widgets.Textarea(value='[[0.00525873615, -0.999894519, 0.0134620306, 46.5174596], [0.999959617, 0.00535678348, -0.00735796480, 32.0776662], [0.00728773209, -0.0135001806, 0.999882310, -4.24772615], [0.0, 0.0, 0.0, 1.0]]', placeholder='[[0.00525873615, -0.999894519, 0.0134620306, 46.5174596], [0.999959617, 0.00535678348, -0.00735796480, 32.0776662], [0.00728773209, -0.0135001806, 0.999882310, -4.24772615], [0.0, 0.0, 0.0, 1.0]]', description='Camera & Robot Calibration Matrix', disabled=False, layout={'width': '99%'}, style=style),            \n",
    "\n",
    "            \"out_prm\": widgets.Textarea(value='', placeholder='', description='API call', disabled=True,  rows=15, layout={'width': '99%'}, style={'description_width': '75px'}),\n",
    "            \"out_return\": widgets.Textarea(value='', placeholder='', description='Return value', disabled=True, rows=5, layout={'width': '99%'}, style={'description_width': '75px'}),\n",
    "\n",
    "            \"close\": widgets.Button( description='Exit App', disabled=False, button_style=\"danger\", tooltip='Exit App', layout={'justify-content': 'flex-end'}),\n",
    "        }\n",
    "\n",
    "class Detection_app(object):\n",
    "    \"\"\"docstring for App\"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Detection_app, self).__init__()\n",
    "        self.retval ={}\n",
    "        self.config = {}\n",
    "\n",
    "        \"\"\"out plot\"\"\"\n",
    "        # close everything first\n",
    "        plt.close('all')\n",
    "        \n",
    "        # Create an initial display with the original image\n",
    "        fig, ax = plt.subplots(frameon=False)\n",
    "        self.plt = {\n",
    "            \"out\":{\n",
    "                \"fig\": fig,\n",
    "                \"ax\": ax,\n",
    "                \"img_plt\": ax.imshow(cv.cvtColor(np.zeros((10, 10), dtype=np.uint8), cv.COLOR_BGR2RGB)),\n",
    "\n",
    "        }}\n",
    "        self.plt[\"out\"][\"fig\"].canvas.header_visible = False\n",
    "        self.plt[\"out\"][\"fig\"].tight_layout()\n",
    "        self.plt[\"out\"][\"ax\"].axis('off')\n",
    "        self.plt[\"out\"][\"img_plt\"].set_visible(False)\n",
    "        \n",
    "        \"\"\"widgets\"\"\"\n",
    "        # widget\n",
    "        self.widget_init = default_widget().widget_init\n",
    "        self.widget_in = default_widget().widget_input\n",
    "        self.widget_tr = default_widget().widget_trigger\n",
    "        self.widget_helper = default_widget().widget_helper\n",
    "        \n",
    "        \"\"\"accordion for adjust the image\"\"\"\n",
    "        # adjust_image\n",
    "        color_picker_box = widgets.HBox([self.widget_tr[k] for k in [key for key in self.widget_tr.keys() if key.startswith('color_')]])\n",
    "        acc_adjust_img = widgets.Accordion()\n",
    "        acc_adjust_img.children = [\n",
    "            widgets.VBox([self.widget_tr[\"source_value\"], self.widget_tr[\"s_file_value\"]]),\n",
    "            widgets.VBox([self.widget_in[k] for k in [key for key in self.widget_in.keys() if key.startswith('roi_')]]),\n",
    "            widgets.VBox([self.widget_in[k] for k in [key for key in self.widget_in.keys() if key.startswith('intensity_')]]),\n",
    "            widgets.VBox([self.widget_in[k] for k in [key for key in self.widget_in.keys() if key.startswith('color_')]]+[widgets.HTML(\"<hr>\")]+[color_picker_box]),\n",
    "        ]\n",
    "        for i, title in enumerate(['Source', 'Region of Interest', 'Intensity', 'Color Mask']):\n",
    "            acc_adjust_img.set_title(i, title)    \n",
    "\n",
    "        \"\"\"init vbox\"\"\"\n",
    "        acc_init_vbox = widgets.Accordion()\n",
    "        acc_init_vbox.children = [\n",
    "            widgets.VBox([self.widget_init[k] for k in [key for key in self.widget_init.keys() if key.startswith('camera_setup_')]]),\n",
    "            widgets.VBox([self.widget_init[k] for k in [key for key in self.widget_init.keys() if key.startswith('frame_')]]),\n",
    "            widgets.VBox([self.widget_init[k] for k in [key for key in self.widget_init.keys() if key.startswith('ml_')]]),\n",
    "        ] \n",
    "        for i, title in enumerate(['1. Camera Mounting', '2. Frame', '3. AI Models']):\n",
    "            acc_init_vbox.set_title(i, title)\n",
    "        \n",
    "        init_vbox = widgets.VBox([\n",
    "            acc_init_vbox,\n",
    "            widgets.HBox([self.widget_init[k] for k in [key for key in [\"init\"]]]),\n",
    "        ])  \n",
    "\n",
    "\n",
    "        \"\"\"method vbox\"\"\"\n",
    "        method_vbox = widgets.VBox([\n",
    "            self.widget_in[\"method_value\"],\n",
    "            widgets.VBox([widgets.HTML(\"<hr>\")]),\n",
    "            widgets.VBox([self.widget_in[k] for k in [key for key in self.widget_in.keys() if key.startswith('m_elp_')]]),\n",
    "            widgets.VBox([self.widget_in[k] for k in [key for key in self.widget_in.keys() if key.startswith('m_poly_')]]),\n",
    "            widgets.VBox([self.widget_in[k] for k in [key for key in self.widget_in.keys() if key.startswith('m_cnt_')]]),\n",
    "            widgets.VBox([self.widget_in[k] for k in [key for key in self.widget_in.keys() if key.startswith('m_aruco_')]]),\n",
    "            widgets.VBox([self.widget_in[k] for k in [key for key in self.widget_in.keys() if key.startswith('m_ocr_')]]),\n",
    "            widgets.VBox([self.widget_in[k] for k in [key for key in self.widget_in.keys() if key.startswith('m_od_')]]),\n",
    "            widgets.VBox([self.widget_in[k] for k in [key for key in self.widget_in.keys() if key.startswith('m_cls_')]]),\n",
    "        ], layout={'width': '100%'})        \n",
    "\n",
    "        \"\"\"method plot\"\"\"\n",
    "        self.method_plt = widgets.Output(layout={'width': '100%'})\n",
    "        with self.method_plt:\n",
    "            # init fig and ax\n",
    "            fig, ax = plt.subplots(frameon=False)\n",
    "            self.plt[\"method\"] = {\n",
    "                \"fig\": fig,\n",
    "                \"ax\": ax,\n",
    "                \"img_plt\": ax.imshow(np.zeros((10, 10), dtype=np.uint8))\n",
    "            }\n",
    "            self.plt[\"method\"][\"fig\"].canvas.header_visible = False\n",
    "            self.plt[\"method\"][\"fig\"].tight_layout()\n",
    "            self.plt[\"method\"][\"fig\"].set_size_inches((4,3), forward=True)\n",
    "            self.plt[\"method\"][\"img_plt\"].set_visible(False)\n",
    "            plt.show()\n",
    "\n",
    "        \"\"\"plane\"\"\"\n",
    "        # plane selector\n",
    "        plane_plot = widgets.Output()\n",
    "        with plane_plot:\n",
    "            # init fig and ax\n",
    "            fig, ax = self.plane_plt()\n",
    "            self.plt[\"plane\"] = {\n",
    "                \"fig\": fig,\n",
    "                \"ax\": ax\n",
    "            }\n",
    "            plt.show()  \n",
    "\n",
    "        # init plane\n",
    "        #self.plane_value = poly_select(self.widget_in[\"plane_value\"])\n",
    "\n",
    "        # Initialize plane selector\n",
    "        #self.plane_selector = PolygonSelector(self.plt[\"plane\"][\"ax\"], onselect=self.plane_value.onselect, useblit=True, props=dict(color='orange', linestyle='--'))\n",
    "        plane_box = widgets.VBox([self.widget_in[\"plane_value\"], plane_plot])\n",
    "\n",
    "        \"\"\"accordion for settings\"\"\"\n",
    "        # acc setting\n",
    "        acc_helper = widgets.Accordion()\n",
    "\n",
    "        acc_helper.children = [\n",
    "            widgets.VBox([self.widget_helper[k] for k in [key for key in self.widget_helper.keys() if key.startswith('xyz_')]]),\n",
    "        ]\n",
    "\n",
    "        for i, title in enumerate([\"Pixel to XYZ\"]):\n",
    "            acc_helper.set_title(i, title)  \n",
    "\n",
    "        \"\"\"accordion for settings\"\"\"\n",
    "        # acc setting\n",
    "        acc_setting = widgets.Accordion()\n",
    "        acc_setting.children = [\n",
    "            widgets.VBox([self.widget_in[k] for k in [key for key in self.widget_in.keys() if key.startswith('2d_range_')]]),\n",
    "            widgets.VBox([self.widget_in[k] for k in [key for key in self.widget_in.keys() if key.startswith('3d_range_')]]),\n",
    "            plane_box,\n",
    "            widgets.VBox([self.widget_in[k] for k in [key for key in self.widget_in.keys() if key.startswith('output_')]]),\n",
    "        ]\n",
    "\n",
    "        for i, title in enumerate([\"2D Limit \", \"3D Limit\", \"6D Pose\", \"Output Format\"]):\n",
    "            acc_setting.set_title(i, title)    \n",
    "\n",
    "\n",
    "        \"\"\"result\"\"\"\n",
    "        result_vbox = widgets.VBox([self.widget_tr[k] for k in [key for key in self.widget_tr.keys() if key.startswith('out_')]])\n",
    "\n",
    "        \"\"\"tab\"\"\"\n",
    "        tabs = [\n",
    "            init_vbox,\n",
    "            acc_adjust_img,\n",
    "            widgets.HBox([method_vbox, self.method_plt]),\n",
    "            acc_setting,\n",
    "            result_vbox,\n",
    "            acc_helper,\n",
    "        ]\n",
    "        self.tab = widgets.Tab()\n",
    "        self.tab.children = tabs\n",
    "\n",
    "        # hide\n",
    "        for i in range(1, len(self.tab.children)):\n",
    "            self.tab.children[i].layout.display = 'none'\n",
    "        \n",
    "        self.tab.set_title(0, 'Initialization')\n",
    "        self.tab.set_title(1, 'Image')\n",
    "        self.tab.set_title(2, 'Detection')\n",
    "        self.tab.set_title(3, 'Setting')\n",
    "        self.tab.set_title(4, 'Result')\n",
    "        self.tab.set_title(5, 'Helper Functions')\n",
    "        \n",
    "        # header\n",
    "        header = widgets.HBox([\n",
    "            self.widget_tr[\"s_apply\"],\n",
    "            self.widget_tr[\"close\"],\n",
    "        ])\n",
    "\n",
    "        # display\n",
    "        display(widgets.VBox([header, self.tab]))\n",
    "\n",
    "        # init parameters\n",
    "        self.widget_init[\"init\"].on_click(self.init_parameter)\n",
    "\n",
    "\n",
    "        \"\"\"roi\"\"\"\n",
    "        # init roi\n",
    "        self.roi_value = poly_select(self.widget_in[\"roi_value\"])\n",
    "\n",
    "        # Initialize PolygonSelector\n",
    "        self.roi_selector = PolygonSelector(self.plt[\"out\"][\"ax\"], onselect=self.roi_value.onselect, useblit=True, props=dict(color='blue', linestyle='--'))\n",
    "\n",
    "        # interactive for source\n",
    "        interactive(self.hide_show_source, source_value=self.widget_tr[\"source_value\"])\n",
    "\n",
    "        # interactive for ip\n",
    "        interactive(self.hide_show_ip, source_value=self.widget_init[\"camera_setup_type\"])\n",
    "\n",
    "        # interactive color_picker\n",
    "        self.widget_tr[\"color_picker\"].observe(self.hex_to_hsv, names='value')\n",
    "        \n",
    "        # capture\n",
    "        self.widget_tr[\"s_apply\"].on_click(self.capture_camera_data)\n",
    "\n",
    "        # capture\n",
    "        #self.widget_tr[\"s_update\"].on_click(self.update_source_list)\n",
    "\n",
    "        # save\n",
    "        self.widget_tr[\"s_save\"].on_click(self.save_as_source)\n",
    "\n",
    "        # close\n",
    "        self.widget_tr[\"close\"].on_click(self.__del__)\n",
    "\n",
    "        # pixel to xyz\n",
    "        self.widget_helper[\"xyz_convert\"].on_click(self.pixel_to_xyz)\n",
    "\n",
    "\n",
    "\n",
    "    def __del__(self, b):\n",
    "        # buttons\n",
    "        self.widget_tr[\"close\"].layout.display = \"none\"\n",
    "        self.widget_tr[\"s_apply\"].layout.display = \"none\"\n",
    "\n",
    "        try:\n",
    "            self.d.camera.close()\n",
    "        except Exception as ex:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            self.d.close()\n",
    "        except Exception as ex:\n",
    "            pass\n",
    "        \n",
    "        # plot\n",
    "        plt.close('all')\n",
    "\n",
    "        # tabs\n",
    "        self.tab.close()\n",
    "\n",
    "\n",
    "    def init_parameter(self, b):\n",
    "        # disable elements in init tab\n",
    "        for k in self.widget_init.keys():\n",
    "            self.widget_init[k].disabled = True\n",
    "        self.widget_init[\"init\"].layout.display = 'none'\n",
    "\n",
    "        # data\n",
    "        self.data = None\n",
    "        \n",
    "        # robot\n",
    "        robot = None\n",
    "        if self.widget_init[\"camera_setup_type\"].value == 0:\n",
    "            try:\n",
    "                robot = Dorna()\n",
    "                robot.connect(self.widget_init[\"camera_setup_robot_ip\"].value)\n",
    "            except Exception as ex:\n",
    "                pass\n",
    "        \n",
    "        # frame\n",
    "        try:\n",
    "            frame = ast.literal_eval(self.widget_init[\"frame_value\"].value)\n",
    "            if len(frame) != 6:\n",
    "                frame = [0, 0, 0, 0, 0, 0]\n",
    "        except Exception as ex:\n",
    "            frame = [0, 0, 0, 0, 0, 0]\n",
    "\n",
    "        # camera\n",
    "        camera = Camera()\n",
    "        try:\n",
    "            camera.connect()\n",
    "        except Exception as ex:\n",
    "            pass\n",
    "        \n",
    "        # detect\n",
    "        self.d = Detection(camera, robot, frame)\n",
    "        \n",
    "        # ocr\n",
    "        self.d.init_ocr()\n",
    "        \n",
    "        # object_detection\n",
    "        ml_detection_path = self.widget_init[\"ml_detection_path\"].value\n",
    "        if ml_detection_path:\n",
    "            if self.widget_init[\"ml_detection_type\"].value == 0:\n",
    "                self.d.init_od(ml_detection_path) \n",
    "                self.widget_in[\"method_value\"].options = list(self.widget_in[\"method_value\"].options) + [(\"Object detection\", 6)]\n",
    "            elif self.widget_init[\"ml_detection_type\"].value == 1:\n",
    "                self.d.init_cls(ml_detection_path) \n",
    "                self.widget_in[\"method_value\"].options = list(self.widget_in[\"method_value\"].options) + [(\"Image classification\", 7)]\n",
    "\n",
    "        # hide element in method\n",
    "        for k in [key for key in self.widget_in.keys() if key.startswith('m_')]:\n",
    "            self.widget_in[k].layout.display = 'none'\n",
    "\n",
    "        # enable capture image\n",
    "        self.widget_tr[\"s_apply\"].disabled = False\n",
    "\n",
    "        # show tabs\n",
    "        for i in range(1, len(self.tab.children)):\n",
    "            self.tab.children[i].layout.display = \"flex\"\n",
    "\n",
    "        # interactive run with no changing data\n",
    "        interactive(self._detect_pattern, **self.widget_in)\n",
    "\n",
    "        # display plot\n",
    "        self.plt[\"out\"][\"img_plt\"].set_visible(True)\n",
    "\n",
    "\n",
    "\n",
    "    def hex_to_hsv(self, change):\n",
    "        # Remove '#' if present\n",
    "        hex_color = change['new'].lstrip('#')\n",
    "\n",
    "        # Convert hex to RGB\n",
    "        rgb_color = tuple(int(hex_color[i:i+2], 16) for i in (0, 2, 4))\n",
    "\n",
    "        # Normalize RGB values to the range [0, 1]\n",
    "        normalized_rgb = tuple(value / 255.0 for value in rgb_color)\n",
    "\n",
    "        # Convert RGB to HSV\n",
    "        hsv_color = colorsys.rgb_to_hsv(*normalized_rgb)\n",
    "\n",
    "        # Adjust HSV values to the common OpenCV conventions\n",
    "        h = int(hsv_color[0] * 179)\n",
    "        s = int(hsv_color[1] * 255)\n",
    "        v = int(hsv_color[2] * 255)\n",
    "        self.widget_tr[\"color_hsv\"].value = f\"Hue = {h}, Saturation = {s}, Value = {v}\"\n",
    "\n",
    "        # color\n",
    "        self.widget_in[\"color_h\"].value = [max(0, h-20), min(179, h+20)]\n",
    "        self.widget_in[\"color_s\"].value = [max(0, s-20), min(255, s+20)]\n",
    "        self.widget_in[\"color_v\"].value = [max(0, v-20), min(255, v+20)]\n",
    "\n",
    "    \n",
    "    def save_as_source(self, b):\n",
    "        file_path = self.widget_tr[\"s_save_path\"].value\n",
    "        \n",
    "        # opencv\n",
    "        cv.imwrite(file_path, self.d.camera_data[\"color_img\"])\n",
    "\n",
    "        \n",
    "    def open_pkl(self, file_path):\n",
    "        with open(file_path, 'rb') as file:\n",
    "            loaded_data = pkl.load(file)\n",
    "        return loaded_data\n",
    "\n",
    "\n",
    "    def pixel_to_xyz(self, b):\n",
    "        width = self.widget_helper[\"xyz_width\"].value\n",
    "        height = self.widget_helper[\"xyz_height\"].value\n",
    "        xyz = self.d.pixel_to_xyz([width, height])\n",
    "        self.widget_helper[\"xyz_xyz\"].value = f\"[{', '.join(f'{value:.1f}' for value in xyz)}]\"\n",
    "\n",
    "\n",
    "    def capture_camera_data(self, b):\n",
    "        self.data = None\n",
    "        if self.widget_tr[\"source_value\"].value == 1: # read from file\n",
    "            # file_path\n",
    "            self.data = self.widget_tr[\"s_file_value\"].value\n",
    "\n",
    "        # call detect pattern\n",
    "        kwargs = {k:self.widget_in[k].value for k in self.widget_in.keys()}\n",
    "        self._detect_pattern(**kwargs)\n",
    "\n",
    "\n",
    "    def update_source_list(self, b):\n",
    "        all_device = self.d.camera.all_device()\n",
    "        \n",
    "        i = 0\n",
    "        options = []\n",
    "        for device in all_device:\n",
    "            options.append((device[\"name\"] +\" (S/N: \"+device[\"serial_number\"], \")\", i))\n",
    "            i += 1\n",
    "        options.append(('Image file', i))\n",
    "        self.widget_tr[\"source_value\"].options = options\n",
    "\n",
    "\n",
    "    def hide_show_source(self, **kwargs):\n",
    "        if kwargs[\"source_value\"] == 1:\n",
    "            self.widget_tr[\"s_file_value\"].layout.display = \"flex\"\n",
    "            #self.widget_tr[\"source_feed\"].layout.display = \"none\"\n",
    "        elif kwargs[\"source_value\"] == 0:\n",
    "            self.widget_tr[\"s_file_value\"].layout.display = \"none\"\n",
    "            #self.widget_tr[\"source_feed\"].layout.display = \"flex\"\n",
    "\n",
    "\n",
    "    def hide_show_ip(self, **kwargs):\n",
    "        if kwargs[\"source_value\"] == 0:\n",
    "            self.widget_init[\"camera_setup_robot_ip\"].layout.display = \"flex\"\n",
    "        elif kwargs[\"source_value\"] == 1:\n",
    "            self.widget_init[\"camera_setup_robot_ip\"].layout.display = \"none\"\n",
    "\n",
    "\n",
    "    def plane_plt(self):\n",
    "        # create\n",
    "        fig, ax = plt.subplots(frameon=False)\n",
    "        #fig.suptitle(\"Select 3 points of interest\")\n",
    "        fig.canvas.header_visible = False\n",
    "        fig.tight_layout()\n",
    "        \n",
    "        # Set the height and calculate the width based on the golden ratio\n",
    "        height = 1.0\n",
    "        width = 1.0\n",
    "\n",
    "        # Draw the ellipse in magenta\n",
    "        ellipse = Ellipse((0, 0), 2 * width, 2 * height, linewidth=1, edgecolor='#FF00FF', facecolor='none')\n",
    "        ax.add_patch(ellipse)\n",
    "\n",
    "        # Draw the minimum bounding box around the ellipse in magenta\n",
    "        min_bounding_box = plt.Rectangle((-width, -height), 2 * width, 2 * height, linewidth=1, edgecolor='#FF00FF', facecolor='none', label='Oriented Bounding Box')\n",
    "        ax.add_patch(min_bounding_box)\n",
    "\n",
    "        # Draw major and minor axes\n",
    "        major_axis = plt.Line2D([0, width], [0, 0], color='red', linestyle='dashed', linewidth=1, label='Major Axis')\n",
    "        minor_axis = plt.Line2D([0, 0], [0, height], color='green', linestyle='dashed', linewidth=1, label='Minor Axis')\n",
    "        ax.add_line(major_axis)\n",
    "        ax.add_line(minor_axis)\n",
    "\n",
    "        # Plot the center of the rectangle in blue\n",
    "        ax.plot(0, 0, marker='o', markersize=6, color='blue', label='Center')\n",
    "\n",
    "        # Set axis limits with x and y axes twice as large\n",
    "        ax.set_xlim(-2 * width, 2 * width)\n",
    "        ax.set_ylim(-2 * height, 2 * height)\n",
    "\n",
    "        # Display the legend\n",
    "        ax.legend()\n",
    "\n",
    "        # Set aspect ratio\n",
    "        ax.set_aspect(1/1.68)\n",
    "\n",
    "        # invert y\n",
    "        ax.invert_yaxis()\n",
    "\n",
    "        # Display the plot\n",
    "        return fig, ax\n",
    "\n",
    "\n",
    "    def api_call(self, prm):\n",
    "        code = textwrap.dedent(\n",
    "f\"\"\"# detection parameters\n",
    "prm = {prm}\n",
    "\n",
    "# create the Detection object\n",
    "detection = Detection(camera=camera, robot=robot, **prm)\n",
    "\n",
    "# call the detection\n",
    "retval = detection.run()\n",
    "\n",
    "# close when no longer needed\n",
    "detection.close()\"\"\")\n",
    "        return code\n",
    "    \n",
    "\n",
    "    def _detect_pattern(self, **kwargs):\n",
    "        try:\n",
    "            # adjust kwargs\n",
    "            prm = {}\n",
    "\n",
    "            # feed\n",
    "            prm[\"feed\"] = self.widget_tr[\"source_feed\"].value\n",
    "            \n",
    "            # intensity\n",
    "            prm[\"intensity\"] = {\"a\": 1.0, \"b\": 0}\n",
    "            if kwargs[\"intensity_enb\"]:\n",
    "                prm[\"intensity\"] = {\"a\": kwargs[\"intensity_a\"], \"b\": kwargs[\"intensity_b\"]}\n",
    "            \n",
    "            # color\n",
    "            prm[\"color\"] = {\"low_hsv\": [0, 0, 0], \"high_hsv\": [255, 255, 255], \"inv\": 0}\n",
    "            if kwargs[\"color_enb\"]:\n",
    "                prm[\"color\"] = {\"low_hsv\": [kwargs[k][0] for k in [\"color_h\", \"color_s\", \"color_v\"]], \"high_hsv\": [kwargs[k][1] for k in [\"color_h\", \"color_s\", \"color_v\"]], \"inv\": kwargs[\"color_inv\"]}\n",
    "            \n",
    "            # roi\n",
    "            prm[\"roi\"] = {\"corners\": [], \"inv\": 0, \"crop\": 0}\n",
    "            if kwargs[\"roi_enb\"]:\n",
    "                prm[\"roi\"] = {\"corners\": ast.literal_eval(kwargs[\"roi_value\"]), \"inv\": kwargs[\"roi_inv\"], \"crop\": kwargs[\"roi_crop\"]}\n",
    "\n",
    "            \n",
    "            # detection\n",
    "            prm[\"detection\"] = {\"cmd\":None} \n",
    "            if kwargs[\"method_value\"] == 1:\n",
    "                prm[\"detection\"] = {\"cmd\":\"elp\", \"min_path_length\": kwargs[\"m_elp_min_path_length\"], \"min_line_length\": kwargs[\"m_elp_min_line_length\"], \"nfa_validation\": kwargs[\"m_elp_nfa_validation\"], \"sigma\": kwargs[\"m_elp_sigma\"], \"gradient_threshold_value\": kwargs[\"m_elp_gradient_threshold_value\"], \"pf_mode\": kwargs[\"m_elp_pf_mode\"]}\n",
    "            elif kwargs[\"method_value\"] == 2:\n",
    "                prm[\"detection\"] = {\"cmd\":\"poly\", \"type\": kwargs[\"m_cnt_type\"], \"inv\": kwargs[\"m_cnt_inv\"], \"blur\": kwargs[\"m_cnt_blur\"], \"thr\": kwargs[\"m_cnt_thr\"], \"mean_sub\": kwargs[\"m_cnt_mean_sub\"], \"side\": kwargs[\"m_poly_side\"]}\n",
    "            elif kwargs[\"method_value\"] == 3:\n",
    "                prm[\"detection\"] = {\"cmd\":\"cnt\", \"type\": kwargs[\"m_cnt_type\"], \"inv\": kwargs[\"m_cnt_inv\"], \"blur\": kwargs[\"m_cnt_blur\"], \"thr\": kwargs[\"m_cnt_thr\"], \"mean_sub\": kwargs[\"m_cnt_mean_sub\"]}\n",
    "            elif kwargs[\"method_value\"] == 4:\n",
    "                prm[\"detection\"] = {\"cmd\":\"aruco\", \"dictionary\": kwargs[\"m_aruco_dictionary\"], \"marker_length\": kwargs[\"m_aruco_marker_length\"], \"refine\": kwargs[\"m_aruco_refine\"] , \"subpix\": kwargs[\"m_aruco_subpix\"]}\n",
    "            elif kwargs[\"method_value\"] == 5:\n",
    "                prm[\"detection\"] = {\"cmd\":\"ocr\", \"conf\": kwargs[\"m_ocr_conf\"]}\n",
    "            elif kwargs[\"method_value\"] == 6:\n",
    "                cls_name =  [item.strip() for item in kwargs[\"m_od_cls\"].split(',') if item.strip()]\n",
    "                prm[\"detection\"] = {\"cmd\":\"od\", \"path\": self.widget_init[\"ml_detection_path\"].value, \"conf\": kwargs[\"m_od_conf\"], \"cls\": cls_name}   \n",
    "            elif kwargs[\"method_value\"] == 7:\n",
    "                prm[\"detection\"] = {\"cmd\":\"cls\", \"path\": self.widget_init[\"ml_detection_path\"].value, \"conf\": kwargs[\"m_cls_conf\"]}   \n",
    "\n",
    "\n",
    "            #limit\n",
    "            prm[\"limit\"] = {\"area\":[], \"aspect_ratio\":[], \"xyz\":[], \"inv\":0}\n",
    "            if kwargs[\"2d_range_enb\"]:\n",
    "                prm[\"limit\"][\"aspect_ratio\"] = kwargs[\"2d_range_aspect_ratio\"]\n",
    "                prm[\"limit\"][\"area\"] = kwargs[\"2d_range_area_range\"]\n",
    "            if kwargs[\"3d_range_enb\"]:\n",
    "                prm[\"limit\"][\"xyz\"] = list(kwargs[\"3d_range_x\"] + kwargs[\"3d_range_y\"] + kwargs[\"3d_range_z\"])\n",
    "            if kwargs[\"3d_range_inv\"]:\n",
    "                prm[\"limit\"][\"inv\"] = 1\n",
    "            \n",
    "            # plane\n",
    "            prm[\"plane\"] = []\n",
    "            if kwargs[\"plane_enb\"]:\n",
    "                prm[\"plane\"] = ast.literal_eval(kwargs[\"plane_value\"])\n",
    "            \n",
    "            # output\n",
    "            prm[\"output\"] = { \"max_det\": kwargs[\"output_max_det\"], \"shuffle\": kwargs[\"output_shuffle\"], \"save_img\": kwargs[\"output_save\"]}\n",
    "\n",
    "            \"\"\"hide and show inputs\"\"\"\n",
    "            show_key = [[key for key in self.widget_in.keys() if key.startswith(term)] for term in [\"m_nothing\", \"m_elp\", \"m_poly\", \"m_cnt\", \"m_aruco\", \"m_ocr\", \"m_od\", \"m_cls\"]][kwargs[\"method_value\"]]\n",
    "            hide_key = [key for key in self.widget_in.keys() if key.startswith('m_') and key not in show_key] \n",
    "            for k in show_key:\n",
    "                if self.widget_in[k].layout.display != \"flex\":\n",
    "                    self.widget_in[k].layout.display = \"flex\"\n",
    "            for k in hide_key:\n",
    "                if self.widget_in[k].layout.display != \"none\":\n",
    "                    self.widget_in[k].layout.display = \"none\"\n",
    "            self.hide_key = hide_key\n",
    "            self.show_key = show_key\n",
    "\n",
    "            # run pattern detection\n",
    "            self.prm = prm\n",
    "            retval = self.d.run(data=self.data, **prm)\n",
    "            self.data = dict(self.d.camera_data)\n",
    "            \n",
    "            # adjust the frame size\n",
    "            self.plt[\"out\"][\"img_plt\"].set_extent([0, self.d.camera_data[prm[\"feed\"]].shape[1], self.d.camera_data[prm[\"feed\"]].shape[0], 0])\n",
    "            self.plt[\"method\"][\"img_plt\"].set_extent([0, self.d.camera_data[prm[\"feed\"]].shape[1], self.d.camera_data[prm[\"feed\"]].shape[0], 0])\n",
    "\n",
    "            # display thr\n",
    "            if kwargs[\"method_value\"] in [2, 3]: # polygon and contour\n",
    "                self.method_plt.clear_output(wait=True)\n",
    "                self.plt[\"method\"][\"img_plt\"].set_visible(True)\n",
    "                self.plt[\"method\"][\"ax\"].axis('on')\n",
    "                self.plt[\"method\"][\"img_plt\"].set_data(self.d.img_thr)\n",
    "            else:      \n",
    "                self.plt[\"method\"][\"img_plt\"].set_visible(False)\n",
    "                self.plt[\"method\"][\"ax\"].axis('off')\n",
    "\n",
    "            # Update the existing plot\n",
    "            self.plt[\"out\"][\"img_plt\"].set_data(cv.cvtColor(self.d.img, cv.COLOR_BGR2RGB))\n",
    "\n",
    "            # Redraw the plot\n",
    "            self.plt[\"out\"][\"fig\"].canvas.draw_idle()\n",
    "            self.plt[\"method\"][\"fig\"].canvas.draw_idle()\n",
    "            \n",
    "            # type retval\n",
    "            self.retval = retval\n",
    "            json_str = json.dumps(retval)\n",
    "            converted_retval = json.loads(json_str, parse_int=lambda x: int(x), parse_float=lambda x: float(x), parse_constant=lambda x: x, object_hook=lambda d: {k: 1 if v is True else 0 if v is False else v for k, v in d.items()}) \n",
    "            self.widget_tr[\"out_return\"].value = json.dumps(converted_retval)\n",
    "\n",
    "            # api call\n",
    "            self.widget_tr[\"out_prm\"].value = self.api_call(prm)\n",
    "            self.config = kwargs\n",
    "            \n",
    "        except Exception as ex:\n",
    "            print(ex)\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e519a317d404dd2a2b7a229e6f6f107",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Button(button_style='success', description='Capture Image', disabled=True, style…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6330101d735c48df93e2b0d224172dcc",
       "version_major": 2,
       "version_minor": 0
      },
      "image/png": "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",
      "text/html": [
       "\n",
       "            <div style=\"display: inline-block;\">\n",
       "                <div class=\"jupyter-widgets widget-label\" style=\"text-align: center;\">\n",
       "                    Figure\n",
       "                </div>\n",
       "                <img src='data:image/png;base64,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' width=640.0/>\n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "Canvas(header_visible=False, toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Bac…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = Detection_app()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#x.widget_in[\"m_cls_conf\"].value\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#x.widget_in[\"m_cls_conf\"].layout.display\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#x.widget_tr[\"out_prm\"].value\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[43mx\u001b[49m\u001b[38;5;241m.\u001b[39mplt\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "#x.widget_in[\"m_cls_conf\"].value\n",
    "#x.widget_in[\"m_cls_conf\"].layout.display\n",
    "#x.widget_tr[\"out_prm\"].value\n",
    "x.plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall:  0.014835357666015625\n",
      "[{'timestamp': 1731222951.2691405, 'cls': 'empty', 'conf': 0.9755034, 'center': [424, 240], 'corners': [[20, 20], [827, 20], [827, 459], [20, 459]], 'xyz': [0, 0, 0], 'rvec': [0, 0, 0], 'tvec': [0, 0, 0]}]\n"
     ]
    }
   ],
   "source": [
    "from detect import Detection\n",
    "from camera import Camera\n",
    "from dorna2 import Dorna\n",
    "import time\n",
    "\n",
    "# camera\n",
    "#camera = Camera()\n",
    "#camera.connect()\n",
    "\n",
    "# robot\n",
    "#robot = Dorna()\n",
    "#robot.connect(\"192.168.254.18\")\n",
    "\n",
    "prm ={'feed': 'color_img',\n",
    " 'intensity': {'a': 1, 'b': 0},\n",
    " 'color': {'low_hsv': [], 'high_hsv': [], 'inv': 0},\n",
    " 'roi': {'corners': [], 'inv': 0, 'crop': 0},\n",
    " 'limit': {'area': [], 'aspect_ratio': [], 'xyz': [], 'inv': 0},\n",
    " 'plane': [],\n",
    " 'detection': {'cmd': \"cls\", 'conf': 0.5, 'path': \"C:/Users/hossein/Downloads/hopper_grain_cs.pkl\"},\n",
    " 'output': {'max_det': 10, 'shuffle': True, 'save_img': True}}\n",
    "#d  = Detection(camera=camera, robot=robot, **prm)\n",
    "d  = Detection(camera=None, robot=None, **prm)\n",
    "s = time.time()\n",
    "retval = d.run(\"C:/Users/hossein/Downloads/img_1726590775.jpg\")\n",
    "print(\"overall: \", time.time() - s)\n",
    "\n",
    "# close\n",
    "#camera.close()\n",
    "#robot.close()\n",
    "print(retval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted XYZ coordinates for test point: [1.69949396e-15 1.10000000e+00 8.80000000e+00]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define your input points and their corresponding targets\n",
    "train_points = np.array([\n",
    "    [0.0, 0.0, 0.0],\n",
    "    [1.0, 0.0, 0.0],\n",
    "    [0.0, 1.0, 0.0],\n",
    "    [0.0, 0.0, 1.0]\n",
    "])\n",
    "\n",
    "train_targets = np.array([\n",
    "    [0.0, 0.0, 0.0],\n",
    "    [8.0, 0.0, 0.0],\n",
    "    [0.0, 8.0, 0.0],\n",
    "    [0.0, 1.0, 8.0]\n",
    "])\n",
    "\n",
    "# Append a column of ones to the input points to account for translation\n",
    "train_points_augmented = np.hstack((train_points, np.ones((train_points.shape[0], 1))))\n",
    "\n",
    "# Solve for the affine transformation matrix\n",
    "# X * T = Y => T = (X.T * X)^-1 * X.T * Y\n",
    "T, _, _, _ = np.linalg.lstsq(train_points_augmented, train_targets, rcond=None)\n",
    "\n",
    "# Define a function to apply the transformation to new points\n",
    "def map_point(point, T):\n",
    "    point_augmented = np.append(point, 1)  # Add the homogeneous coordinate\n",
    "    mapped_point = np.dot(point_augmented, T)\n",
    "    return mapped_point\n",
    "\n",
    "# Test the transformation on a new point\n",
    "test_point = np.array([0.0, 0.0, 1.1])\n",
    "predicted_xyz = map_point(test_point, T)\n",
    "\n",
    "print(\"Predicted XYZ coordinates for test point:\", predicted_xyz)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dorna_vision' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdorna_vision\u001b[49m\u001b[38;5;241m.\u001b[39mutil\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__file__\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dorna_vision' is not defined"
     ]
    }
   ],
   "source": [
    "dorna_vision.util.__file__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
