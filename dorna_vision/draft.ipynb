{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interactive, widgets\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "from matplotlib.widgets import PolygonSelector\n",
    "from matplotlib.backend_bases import MouseEvent\n",
    "\n",
    "import ast\n",
    "from camera import Camera\n",
    "import pickle as pkl\n",
    "\n",
    "from dorna_vision.draw import *\n",
    "from dorna_vision.util import *\n",
    "#from dorna_vision.detect import *\n",
    "\n",
    "########################################################\n",
    "########################################################\n",
    "\n",
    "#??? method_value to run, abd\n",
    "import json\n",
    "import cv2 as cv\n",
    "from dorna_vision.util import *\n",
    "from dorna_vision.draw import *\n",
    "from ai import * #???? change this to from dorna_vision.ai import *\n",
    "import os\n",
    "import time\n",
    "import threading\n",
    "import numpy as np\n",
    "\n",
    "class Detection(object):\n",
    "    \"\"\"docstring for Detect\"\"\"\n",
    "    def __init__(self, robot=None, camera=None, model_path=None):\n",
    "        super(Detection, self).__init__()\n",
    "        \n",
    "        # init camera and robot and calib matrix \n",
    "        self.camera = camera\n",
    "        self.robot = robot\n",
    "        \n",
    "        # pattern config ???\n",
    "        self.config = {\"poi_value\": [], \"color_enb\": 0, \"color_h\": [60, 120], \"color_s\": [85, 170], \"color_v\": [85, 170], \"color_inv\": 0, \"roi_enb\": 0, \"roi_value\": [[353.84, 171.66], [324.84, 524.06], [828.9, 564.2], [811.06, 180.58]], \"roi_inv\": 0, \"intensity_enb\": 0, \"intensity_alpha\": 2.0, \"intensity_beta\": 50, \"method_value\": 0, \"m_elp_pf_mode\": 0, \"m_elp_nfa_validation\": 1, \"m_elp_min_path_length\": 50, \"m_elp_min_line_length\": 10, \"m_elp_sigma\": 1, \"m_elp_gradient_threshold_value\": 20, \"m_elp_axes\": [20, 100], \"m_elp_ratio\": [0.0, 1.0], \"m_circle_inv\": 1, \"m_circle_type\": 0, \"m_circle_thr\": 127, \"m_circle_blur\": 3, \"m_circle_mean_sub\": 0, \"m_circle_radius\": [1, 30], \"m_poly_inv\": 1, \"m_poly_type\": 0, \"m_poly_thr\": 127, \"m_poly_blur\": 3, \"m_poly_mean_sub\": 0, \"m_poly_value\": 3, \"m_poly_area\": [100, 100000], \"m_poly_perimeter\": [10, 100000], \"m_cnt_inv\": 1, \"m_cnt_type\": 0, \"m_cnt_thr\": 127, \"m_cnt_blur\": 3, \"m_cnt_mean_sub\": 0, \"m_cnt_area\": [100, 100000], \"m_cnt_perimeter\": [10, 100000], \"m_aruco_dictionary\": \"DICT_6X6_250\", \"m_aruco_marker_length\": 10, \"m_aruco_refine\": \"CORNER_REFINE_NONE\", \"m_aruco_subpix\": 0, \"m_od_model_path\":\"\"}\n",
    "\n",
    "        # object_detection\n",
    "        self.od = Object_detection(model_path)\n",
    "        \n",
    "        # ocr\n",
    "        self.ocr = Ocr()\n",
    "        \n",
    "        # thread list\n",
    "        self.thread_list = []\n",
    "\n",
    "        self.adjust_img = np.zeros((10, 10))\n",
    "\n",
    "\n",
    "    def update_camera_data(self):\n",
    "        depth_frame, ir_frame, color_frame, depth_img, ir_img, color_img, depth_int, frames, timestamp = self.camera.get_all()\n",
    "        self.camera_data = {\n",
    "            \"depth_frame\": depth_frame,\n",
    "            \"ir_frame\": ir_frame,\n",
    "            \"color_frame\": color_frame,\n",
    "            \"depth_img\": depth_img,\n",
    "            \"ir_img\": ir_img,\n",
    "            \"color_img\": color_img,\n",
    "            \"depth_int\": depth_int,\n",
    "            \"frames\": frames,\n",
    "            \"timestamp\": timestamp\n",
    "        }\n",
    "        return self.camera_data\n",
    "\n",
    "\n",
    "    def img(self):\n",
    "        return self.adjust_img\n",
    "\n",
    "\n",
    "    def run(self, prm=None, save_path=None):        \n",
    "        # camera data\n",
    "        camera_data = self.update_camera_data()\n",
    "\n",
    "        # roi\n",
    "\n",
    "        # color\n",
    "\n",
    "        # intensity\n",
    "\n",
    "        # detection\n",
    "\n",
    "        # threshould\n",
    "\n",
    "        # pose\n",
    "\n",
    "        # return\n",
    "\n",
    "        # run pattern detection\n",
    "        timestamp, retval, adjust_img, thr_img, bgr_img = self._pattern(self.camera, camera_data, **kwargs)\n",
    "        self.adjust_img = adjust_img\n",
    "\n",
    "        # save the plots\n",
    "        if save_path:\n",
    "            # Create a thread to perform the file write operation\n",
    "            thread = threading.Thread(target=cv.imwrite, args=(save_path, adjust_img))\n",
    "            thread.start()\n",
    "\n",
    "            self.thread_list.append(thread)\n",
    "\n",
    "        return retval\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    timestamp\n",
    "    cls\n",
    "    conf\n",
    "    corners\n",
    "    xyz\n",
    "    rvec\n",
    "    tvec\n",
    "    \"\"\"\n",
    "    def _pattern(self, camera, camera_data, **kwargs):\n",
    "        # init retval\n",
    "\n",
    "        retval = []\n",
    "        \"\"\"bgr_img\"\"\"\n",
    "        bgr_img = camera_data[\"color_img\"]\n",
    "\n",
    "        \"\"\"adjust and out img\"\"\"\n",
    "        adjust_img = bgr_img.copy()\n",
    "        thr_img = bgr_img.copy()\n",
    "\n",
    "        # intensity\n",
    "        if kwargs[\"intensity_enb\"]:\n",
    "            adjust_img = intensity(adjust_img, kwargs[\"intensity_alpha\"], kwargs[\"intensity_beta\"])\n",
    "                \n",
    "        # color mask\n",
    "        if kwargs[\"color_enb\"]:\n",
    "            adjust_img = color_mask(adjust_img, (kwargs[\"color_h\"][0], kwargs[\"color_s\"][0], kwargs[\"color_v\"][0]), (kwargs[\"color_h\"][1], kwargs[\"color_s\"][1], kwargs[\"color_v\"][1]), kwargs[\"color_inv\"])\n",
    "\n",
    "        # roi\n",
    "        mask_img = adjust_img.copy()\n",
    "        if kwargs[\"roi_enb\"]:\n",
    "            mask_img = roi_mask(mask_img, kwargs[\"roi_value\"], kwargs[\"roi_inv\"])\n",
    "\n",
    "        \"\"\"methods\"\"\"\n",
    "        # method\n",
    "        if kwargs[\"method_value\"] == 0: # ellipse\n",
    "            # edge drawing\n",
    "            elps = edge_drawing(mask_img, min_path_length=kwargs[\"m_elp_min_path_length\"], min_line_length=kwargs[\"m_elp_min_line_length\"], nfa_validation=kwargs[\"m_elp_nfa_validation\"], sigma=kwargs[\"m_elp_sigma\"], gradient_threshold_value=kwargs[\"m_elp_gradient_threshold_value\"], pf_mode=kwargs[\"m_elp_pf_mode\"], axes=kwargs[\"m_elp_axes\"], ratio=kwargs[\"m_elp_ratio\"])\n",
    "            \n",
    "            # draw elps\n",
    "            draw_ellipse(adjust_img, elps, axis=False)\n",
    "            \n",
    "            # corners\n",
    "            corners = [get_obb_corners(elp[0], [2*elp[1][0], 2*elp[1][1]], elp[2]) for elp in elps]\n",
    "\n",
    "            # return\n",
    "            retval = [\n",
    "                {\"timestamp\": camera_data[\"timestamp\"],\n",
    "                \"cls\": 0,\n",
    "                \"conf\":1,\n",
    "                \"corners\": corners[i],\n",
    "                \"xyz\": [0, 0, 0],\n",
    "                \"rvec\": [0, 0, 0],\n",
    "                \"tvec\": [0, 0, 0],\n",
    "                } for elp in elps\n",
    "            ]\n",
    "            for ret in retval:\n",
    "                #??? center is not given\n",
    "                draw_obb(adjust_img, ret[\"id\"], ret[\"center\"], ret[\"corners\"])\n",
    "\n",
    "        elif kwargs[\"method_value\"] == 2: # polygon\n",
    "            # thr\n",
    "            thr_img = binary_thr(mask_img, kwargs[\"m_poly_type\"], kwargs[\"m_poly_inv\"], kwargs[\"m_poly_blur\"], kwargs[\"m_poly_thr\"], kwargs[\"m_poly_mean_sub\"])\n",
    "\n",
    "            # find contour\n",
    "            draws = find_cnt(thr_img, kwargs[\"m_poly_area\"], kwargs[\"m_poly_perimeter\"], kwargs[\"m_poly_value\"])\n",
    "\n",
    "            # draw contours\n",
    "            draw_cnt(adjust_img, draws, axis=False)\n",
    "\n",
    "            # corners\n",
    "            corners = [get_obb_corners(draw[0], draw[1], draw[2]) for draw in draws]\n",
    "\n",
    "            # return\n",
    "            retval = [\n",
    "                {\"timestamp\": camera_data[\"timestamp\"],\n",
    "                \"cls\":0,\n",
    "                \"conf\":1,\n",
    "                \"corners\": corners[i],\n",
    "                \"xyz\": [0, 0, 0],\n",
    "                \"rvec\": [0, 0, 0],\n",
    "                \"tvec\": [0, 0, 0],\n",
    "                } for draw in draws\n",
    "            ]\n",
    "            for ret in retval:\n",
    "                # ??? center is not valid\n",
    "                draw_obb(adjust_img, ret[\"id\"], ret[\"center\"], ret[\"corners\"])\n",
    "        \n",
    "        elif kwargs[\"method_value\"] == 3: # contour\n",
    "            # thr\n",
    "            thr_img = binary_thr(mask_img, kwargs[\"m_cnt_type\"], kwargs[\"m_cnt_inv\"], kwargs[\"m_cnt_blur\"], kwargs[\"m_cnt_thr\"], kwargs[\"m_cnt_mean_sub\"])\n",
    "\n",
    "            # find contour\n",
    "            draws = find_cnt(thr_img, kwargs[\"m_cnt_area\"], kwargs[\"m_cnt_perimeter\"])\n",
    "\n",
    "            # draw contours\n",
    "            out_img = draw_cnt(adjust_img, draws, axis=False)\n",
    "\n",
    "            # corners\n",
    "            corners = [get_obb_corners(draw[0], draw[1], draw[2]) for draw in draws]\n",
    "\n",
    "            # return\n",
    "            retval = [\n",
    "                {\"timestamp\": camera_data[\"timestamp\"],\n",
    "                \"cls\": 0,\n",
    "                \"conf\":1,\n",
    "                \"corners\": corners[i],\n",
    "                \"xyz\": [0, 0, 0],\n",
    "                \"rvec\": [0, 0, 0],\n",
    "                \"tvec\": [0, 0, 0],\n",
    "                } for draw in draws\n",
    "            ]\n",
    "            for ret in retval:\n",
    "                # ??? adjust center\n",
    "                draw_obb(adjust_img, ret[\"id\"], ret[\"center\"], ret[\"corners\"])\n",
    "        \n",
    "        elif kwargs[\"method_value\"] == 4: # aruco #??? echck this the id does not match\n",
    "            retval = []\n",
    "\n",
    "            # pose: [id, corner, rvec, tvec]\n",
    "            aruco_data = find_aruco(mask_img, camera.camera_matrix(camera_data[\"depth_int\"]), camera.dist_coeffs(camera_data[\"depth_int\"]), kwargs[\"m_aruco_dictionary\"], kwargs[\"m_aruco_marker_length\"], kwargs[\"m_aruco_refine\"], kwargs[\"m_aruco_subpix\"])\n",
    "\n",
    "            for i in range(len(aruco_data)):\n",
    "                _id = int(aruco_data[i][0][0])\n",
    "                _timestamp = camera_data[\"timestamp\"]\n",
    "\n",
    "                # corner and center\n",
    "                _corners = aruco_data[i][1].reshape((4,2))\n",
    "                _center = [int(sum([c[0] for c in _corners])/4), int(sum([c[1] for c in _corners])/4)]\n",
    "                _corners = [[int(c[0]), int(c[1])] for c in _corners]\n",
    "                \n",
    "                # rvec, tvec\n",
    "                _rvec = aruco_data[i][2][0].tolist()\n",
    "                _rvec = [r*180/np.pi for r in _rvec]\n",
    "                _tvec = aruco_data[i][3][0].tolist()\n",
    "                \n",
    "                retval.append({\n",
    "                    \"id\":i,\n",
    "                    \"center\": _center,\n",
    "                    \"corners\": _corners,\n",
    "                    \"xyz\": [0, 0, 0],\n",
    "                    \"rvec\": _rvec,\n",
    "                    \"tvec\": _tvec\n",
    "                    })\n",
    "\n",
    "            # draw\n",
    "            draw_aruco(adjust_img, aruco_data, camera.camera_matrix(camera_data[\"depth_int\"]), camera.dist_coeffs(camera_data[\"depth_int\"]))\n",
    "\n",
    "        if kwargs[\"run\"] == \"ocr\": # ocr\n",
    "            retval = self.ocr.ocr(mask_img, conf=kwargs[\"conf\"])\n",
    "        if kwargs[\"run\"] == \"od\": # object detection\n",
    "            # run detection\n",
    "            objects = self.od(mask_img, **kwargs)\n",
    "            \n",
    "            # format the result\n",
    "            retval = [\n",
    "                        {\"timestamp\": camera_data[\"timestamp\"],\n",
    "                        \"cls\": obj.cls,\n",
    "                        \"label\": self.od[\"classes\"][obj.cls],\n",
    "                        \"conf\": obj.conf,\n",
    "                        \"corners\": [[obj.rect.x, obj.rect.y], [obj.rect.x+obj.rect.w, obj.rect.y], [obj.rect.x+obj.rect.w, obj.rect.y+obj.rect.h], [obj.rect.x, obj.rect.y+obj.rect.h]],\n",
    "                        \"xyz\": [0, 0, 0],\n",
    "                        \"rvec\": [0, 0, 0],\n",
    "                        \"tvec\": [0, 0, 0],\n",
    "                        }\n",
    "                    for obj in objects\n",
    "            ]\n",
    "            \n",
    "            # edge drawing\n",
    "            results = edge_drawing(mask_img, min_path_length=kwargs[\"m_elp_min_path_length\"], min_line_length=kwargs[\"m_elp_min_line_length\"], nfa_validation=kwargs[\"m_elp_nfa_validation\"], sigma=kwargs[\"m_elp_sigma\"], gradient_threshold_value=kwargs[\"m_elp_gradient_threshold_value\"], pf_mode=kwargs[\"m_elp_pf_mode\"], axes=kwargs[\"m_elp_axes\"], ratio=kwargs[\"m_elp_ratio\"])\n",
    "            \n",
    "            # draw elps\n",
    "            draw_ellipse(adjust_img, elps, axis=False)\n",
    "            \n",
    "            # corners\n",
    "            corners = [get_obb_corners(elp[0], [2*elp[1][0], 2*elp[1][1]], elp[2]) for elp in elps]\n",
    "\n",
    "            # return\n",
    "            retval = [\n",
    "                {\"timestamp\": camera_data[\"timestamp\"],\n",
    "                \"cls\": 0,\n",
    "                \"conf\":1,\n",
    "                \"corners\": corners[i],\n",
    "                \"xyz\": [0, 0, 0],\n",
    "                \"rvec\": [0, 0, 0],\n",
    "                \"tvec\": [0, 0, 0],\n",
    "                } for elp in elps\n",
    "            ]\n",
    "            for ret in retval:\n",
    "                #??? center is not given\n",
    "                draw_obb(adjust_img, ret[\"id\"], ret[\"center\"], ret[\"corners\"])\n",
    "\n",
    "        # xyz:\n",
    "        if camera_data[\"depth_frame\"] is not None:\n",
    "            for i in range(len(retval)):\n",
    "                # xyz\n",
    "                retval[i][\"xyz\"] = camera.xyz(retval[i][\"center\"], camera_data[\"depth_frame\"], camera_data[\"depth_int\"])[0].tolist()\n",
    "\n",
    "        # pose\n",
    "        if kwargs[\"method_value\"] in [0, 1, 2, 3]:\n",
    "            # tmp pixels from poi\n",
    "            tmp_pxls = np.array(kwargs[\"poi_value\"])\n",
    "            \n",
    "            if len(tmp_pxls) > 2 and camera_data[\"depth_frame\"] is not None:\n",
    "                for i in range(len(retval)):\n",
    "\n",
    "                    # axis\n",
    "                    center = retval[i][\"center\"]\n",
    "                    dim = retval[i][\"obb\"][\"wh\"] # (w, h)\n",
    "                    rot = retval[i][\"obb\"][\"rot\"]\n",
    "                    del retval[i][\"obb\"]\n",
    "                    \n",
    "                    # pose from tmp\n",
    "                    valid, center_3d, X, Y, Z, pxl_map = pose_3_point(camera_data[\"depth_frame\"], camera_data[\"depth_int\"], tmp_pxls, center, dim, rot, camera)\n",
    "\n",
    "                    if valid: # add pose\n",
    "                        draw_3d_axis(adjust_img, center_3d, X, Y, Z, camera.camera_matrix(camera_data[\"depth_int\"]), camera.dist_coeffs(camera_data[\"depth_int\"]))\n",
    "                        \n",
    "                        retval[i][\"tvec\"] = center_3d.tolist()\n",
    "                        rodrigues, _= cv.Rodrigues(np.matrix([[X[0], Y[0], Z[0]],\n",
    "                                                [X[1], Y[1], Z[1]],\n",
    "                                                [X[2], Y[2], Z[2]]])) \n",
    "                        retval[i][\"rvec\"] = [rodrigues[i, 0]*180/np.pi for i in range(3)]\n",
    "                    \n",
    "\n",
    "                    # draw template\n",
    "                    for pxl in pxl_map:\n",
    "                        draw_point(adjust_img, pxl)\n",
    "\n",
    "        return camera_data[\"timestamp\"], retval, adjust_img, thr_img, bgr_img\n",
    "\n",
    "########################################################\n",
    "########################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class default_widget(object):\n",
    "    \"\"\"docstring for ClassName\"\"\"\n",
    "    def __init__(self,):\n",
    "        super(default_widget, self).__init__()\n",
    "        continuous_update = False\n",
    "        style={'description_width': '150px'}\n",
    "        self.widget_input = {\n",
    "            \"poi_label\": widgets.Label(value=\"Select 3 points relative to the oriented bounding box to define a hyperplane and determine the 6D pose of the detected item.\", layout={'width': '99%'}, style=style),\n",
    "            \"poi_enb\": widgets.Checkbox(value=False, description='Apply the 6D-pose', continuous_update=continuous_update, layout={'width': '99%'}, style=style),\n",
    "            \"poi_value\": widgets.Text(value=\"[]\", placeholder='[]', description='POI', disabled=True, layout={'width': '99%'}, style=style),\n",
    "            \n",
    "            \"color_label\": widgets.Label(value=\"Apply a color mask to filter specific colors by adjusting hue, saturation, and value. Fine-tune these settings to isolate the desired color range for better detection results.\", layout={'width': '99%'}, style=style),\n",
    "            \"color_enb\": widgets.Checkbox(value=False, description='Apply the color mask', continuous_update=continuous_update, layout={'width': '99%'}, style=style),\n",
    "            \"color_h\": widgets.IntRangeSlider(value=[60, 120], min=0, max=179, step=1, description='Hue', continuous_update=continuous_update, layout={'width': '99%'}, style=style),\n",
    "            \"color_s\": widgets.IntRangeSlider(value=[85, 170], min=0, max=255, step=1, description='Saturation', continuous_update=continuous_update, layout={'width': '99%'}, style=style),\n",
    "            \"color_v\": widgets.IntRangeSlider(value=[85, 170], min=0, max=255, step=1, description='Vue', continuous_update=continuous_update, layout={'width': '99%'}, style=style),\n",
    "            \"color_inv\": widgets.Checkbox(value=False, description='Invert the mask', continuous_update=continuous_update, layout={'width': '99%'}, style=style),\n",
    "\n",
    "            \"roi_label\": widgets.Label(value=\"Select the region of interest where the detection method is applied. Use the blue polygon selector on the output image to define this area.\", layout={'width': '99%'}, style=style),\n",
    "            \"roi_enb\": widgets.Checkbox(value=False, description='Apply the ROI', continuous_update=continuous_update, layout={'width': '99%'}, style=style),\n",
    "            \"roi_value\": widgets.Text(value='[]', placeholder='[]', description='ROI', disabled=True, layout={'width': '99%'}, style=style),\n",
    "            \"roi_inv\": widgets.Checkbox(value=False, description='Invert the region', continuous_update=continuous_update, layout={'width': '99%'}, style=style),\n",
    "\n",
    "            \"intensity_label\": widgets.Label(value=\"Adjust brightness and contrast if necessary to enhance image details. Use the sliders for optimal visibility and improved detection results.\", layout={'width': '99%'}, style=style),\n",
    "            \"intensity_enb\": widgets.Checkbox(value=False, description='Apply the intensity', continuous_update=continuous_update, layout={'width': '99%'}, style=style),\n",
    "            \"intensity_alpha\" : widgets.FloatSlider(value=2, min=0, max=4, step=0.01, description='Contrast', continuous_update=continuous_update, layout={'width': '99%'}, style=style),\n",
    "            \"intensity_beta\" : widgets.IntSlider(value=50, min=0, max=255, step=1, description='Brightness', continuous_update=continuous_update, layout={'width': '99%'}, style=style),\n",
    "\n",
    "            \"2d_range_label\": widgets.Label(value=\"Set constraints on the detected item's oriented bounding box aspect ratio and largest dimension to refine detection accuracy.\", layout={'width': '99%'}, style=style),\n",
    "            \"2d_range_enb\": widgets.Checkbox(value=False, description='Apply the size constraints', continuous_update=continuous_update,layout={'width': '99%'}, style=style),\n",
    "            \"2d_range_aspect_ratio\": widgets.FloatRangeSlider(value=[0, 1], min=0, max=1, step=0.01, description='Aspect ratio', continuous_update=continuous_update, layout={'width': '99%'}, style=style),\n",
    "            \"2d_range_size_range\": widgets.IntRangeSlider(value=[0, 1280], min=0, max=1280, step=10, description='Largest dimension (px)', continuous_update=continuous_update, layout={'width': '99%'}, style=style),\n",
    "\n",
    "            \"3d_range_label\": widgets.Label(value=\"Apply spatial constraints to remove detected items outside the specified x, y, z range relative to the frame.\", layout={'width': '99%'}, style=style),\n",
    "            \"3d_range_enb\": widgets.Checkbox(value=False, description='Apply the spatial constraints', continuous_update=continuous_update, layout={'width': '99%'}, style=style),\n",
    "            \"3d_range_x\": widgets.IntRangeSlider(value=[250, 350], min=-750, max=750, step=1, description='x (mm)', continuous_update=continuous_update, layout={'width': '99%'}, style=style),\n",
    "            \"3d_range_y\": widgets.IntRangeSlider(value=[0, 50], min=-750, max=750, step=1, description='y (mm)', continuous_update=continuous_update, layout={'width': '99%'}, style=style),\n",
    "            \"3d_range_z\": widgets.IntRangeSlider(value=[0, 50], min=-750, max=750, step=1, description='z (mm)', continuous_update=continuous_update, layout={'width': '99%'}, style=style),\n",
    "            \"3d_range_inv\": widgets.Checkbox(value=False, description='Invert the range', continuous_update=continuous_update, layout={'width': '99%'}, style=style),\n",
    "\n",
    "            \"method_value\": widgets.Dropdown(value=0, options=[('Ellipse detection', 0), ('Polygon detection', 2), ('Contour detection', 3), ('Aruco detection', 4), ('OCR detection', 5), ('Object detection', 6),], description='Detection method', continuous_update=continuous_update, style=style),\n",
    "    \n",
    "            \"m_elp_pf_mode\": widgets.Checkbox(value=False, description='Auto detection', continuous_update=continuous_update,layout={'width': '99%'}, style=style),\n",
    "            \"m_elp_nfa_validation\": widgets.Checkbox(value=True, description='False alarm validation', continuous_update=continuous_update, layout={'width': '99%'}, style=style),\n",
    "            \"m_elp_min_path_length\": widgets.IntSlider(value=50, min=1, max=1000, step=1, description='Min path length', continuous_update=continuous_update, layout={'width': '99%'}, style=style),\n",
    "            \"m_elp_min_line_length\": widgets.IntSlider(value=10, min=1, max=1000, step=1, description='Min line length', continuous_update=continuous_update, layout={'width': '99%'}, style=style),\n",
    "            \"m_elp_sigma\": widgets.IntSlider(value=1, min=0, max=20, step=0.1, description='Blur', continuous_update=continuous_update, layout={'width': '99%'}, style=style),\n",
    "            \"m_elp_gradient_threshold_value\": widgets.IntSlider(value=20, min=1, max=100, step=1, description='Gradient', continuous_update=continuous_update, layout={'width': '99%'}, style=style),\n",
    "    \n",
    "\n",
    "            \"m_poly_inv\": widgets.Checkbox(value=True, description='Inverse', continuous_update=continuous_update, layout={'width': '99%'}, style=style),\n",
    "            \"m_poly_type\": widgets.Dropdown(value=0, options=[('0: Otsu (auto)', 0), ('1: Binary', 1), ('2: Gaussian', 2)], description='Type', continuous_update=continuous_update, layout={'width': '99%'}, style=style),\n",
    "            \"m_poly_thr\" : widgets.IntSlider(value=127, min=0, max=255, step=1, description='Threshold value', continuous_update=continuous_update, layout={'width': '99%'}, style=style),\n",
    "            \"m_poly_blur\": widgets.IntSlider(value=3, min=1, max=20, step=1, description='Smoothing blur', continuous_update=continuous_update, layout={'width': '99%'}, style=style),                    \n",
    "            \"m_poly_mean_sub\": widgets.IntSlider(value=0, min=-200, max=200, step=1, description='Mean subtract', continuous_update=continuous_update, layout={'width': '99%'}, style=style),\n",
    "            \"m_poly_value\" : widgets.IntSlider(value=3, min=3, max=20, step=1, description='Sides', continuous_update=continuous_update, layout={'width': '99%'}, style=style),\n",
    "\n",
    "            \n",
    "            \"m_cnt_inv\": widgets.Checkbox(value=True, description='Inverse', continuous_update=continuous_update, layout={'width': '99%'}, style=style),\n",
    "            \"m_cnt_type\": widgets.Dropdown(value=0, options=[('0: Otsu (auto)', 0), ('1: Binary', 1), ('2: Gaussian', 2)], description='Type', continuous_update=continuous_update, layout={'width': '99%'}, style=style),\n",
    "            \"m_cnt_thr\" : widgets.IntSlider(value=127, min=0, max=255, step=1, description='Threshold value', continuous_update=continuous_update, layout={'width': '99%'}, style=style),\n",
    "            \"m_cnt_blur\": widgets.IntSlider(value=3, min=1, max=20, step=1, description='Smoothing blur', continuous_update=continuous_update, layout={'width': '99%'}, style=style),                    \n",
    "            \"m_cnt_mean_sub\": widgets.IntSlider(value=0, min=-200, max=200, step=1, description='Mean subtract', continuous_update=continuous_update, layout={'width': '99%'}, style=style),\n",
    "\n",
    "            \"m_aruco_dictionary\":widgets.Dropdown(value=\"DICT_6X6_250\", options= [\"DICT_4X4_50\", \"DICT_4X4_100\", \"DICT_4X4_250\", \"DICT_4X4_1000\", \"DICT_5X5_50\", \"DICT_5X5_100\", \"DICT_5X5_250\", \"DICT_5X5_1000\", \"DICT_6X6_50\", \"DICT_6X6_100\", \"DICT_6X6_250\", \"DICT_6X6_1000\", \"DICT_7X7_50\", \"DICT_7X7_100\", \"DICT_7X7_250\", \"DICT_7X7_1000\", \"DICT_ARUCO_ORIGINAL\", \"DICT_APRILTAG_16h5\", \"DICT_APRILTAG_25h9\", \"DICT_APRILTAG_36h10\", \"DICT_APRILTAG_36h11\"], description='Dictionary', continuous_update=continuous_update, layout={'width': '99%'}, style=style),\n",
    "            \"m_aruco_marker_length\": widgets.IntSlider(value=10, min=1, max=100, step=1, description='Marker length (mm)', continuous_update=continuous_update, layout={'width': '99%'}, style=style),\n",
    "            \"m_aruco_refine\":widgets.Dropdown(value=\"CORNER_REFINE_APRILTAG\", options=[\"CORNER_REFINE_NONE\", \"CORNER_REFINE_SUBPIX\", \"CORNER_REFINE_CONTOUR\", \"CORNER_REFINE_APRILTAG\"], description='Refinement', continuous_update=continuous_update, layout={'width': '99%'}, style=style),\n",
    "            \"m_aruco_subpix\": widgets.Checkbox(value=False, description='Sub pixel', continuous_update=continuous_update, layout={'width': '99%'}, style=style),            \n",
    "\n",
    "            \"m_ocr_crop\": widgets.Checkbox(value=False, description='Crop ROI', continuous_update=continuous_update, layout={'width': '99%'}, style=style),\n",
    "            \"m_ocr_conf\" : widgets.FloatSlider(value=0.5, min=0.01, max=0.99, step=0.01, description='Confidence', continuous_update=continuous_update, layout={'width': '99%'}, style=style), \n",
    "\n",
    "            \"m_od_crop\": widgets.Checkbox(value=False, description='Crop ROI', continuous_update=continuous_update, layout={'width': '99%'}, style=style),\n",
    "            \"m_od_conf\" : widgets.FloatSlider(value=0.5, min=0.01, max=0.99, step=0.01, description='Confidence', continuous_update=continuous_update, layout={'width': '99%'}, style=style), \n",
    "            \"m_od_max_det\" : widgets.IntSlider(value=10, min=1, max=100, step=1, description='Max detection', continuous_update=continuous_update, layout={'width': '99%'}, style=style), \n",
    "            \"m_od_cls\" : widgets.Text(value=\"[]\", placeholder='[]', description='Detection classes', disabled=False, layout={'width': '99%'}, style=style), \n",
    "\n",
    "        }\n",
    "        self.widget_trigger = {\n",
    "            \"color_picker\": widgets.ColorPicker(concise=False, description='Color picker', value='blue', disabled=False, style={'text_width': '0'}),\n",
    "            \"color_hsv\": widgets.Text(value='Hue = 119, Saturation = 255, Value = 255', placeholder='', description='', disabled=True, layout={'width': '99%'}),            \n",
    "\n",
    "            \"source_value\": widgets.Dropdown(value=0, options=[('Stereo camera', 0)], description='Camera', continuous_update=continuous_update, layout={'layout': '99%'}),\n",
    "            \"s_file_value\": widgets.Text(value='', placeholder='Path to the file (*.jpg, *.jpeg, *.png, *.tiff, ...).Ex: test.jpg', description='File path', disabled=False, layout={'width': '99%'}),            \n",
    "            \"s_apply\": widgets.Button( description='Capture Image', disabled=False, button_style=\"\", tooltip='Capture Image'),\n",
    "            \"s_update\": widgets.Button( description='', disabled=False, button_style=\"\", tooltip='Update source list', icon='refresh', layout={'width': '50px'}),\n",
    "            \"s_save_path\": widgets.Text(value='', placeholder='*.jpg', description='Save image as', disabled=False, layout={'width': '99%'}),            \n",
    "            \"s_save\": widgets.Button( description='Save', disabled=False, button_style=\"\", tooltip='Save as'),\n",
    "\n",
    "            #\"model_path\": widgets.Text(value='', placeholder='/full_path/to_the/object_detection_model.pkl', description='Object Detection Model', disabled=False, layout={'width': '99%'}, style=style),            \n",
    "            #\"model_save\": widgets.Button( description='Set', disabled=False, button_style=\"\", tooltip='Set'),\n",
    "\n",
    "            #\"robot_ip\": widgets.Text(value='', placeholder='192.168.254.10', description='Robot IP Address', disabled=False, layout={'width': '99%'}, style=style),            \n",
    "            #\"robot_connect\": widgets.Button( description='Connect', disabled=False, button_style=\"\", tooltip='Connect'),\n",
    "\n",
    "            #\"camera_robot_calibration\": widgets.Textarea(value='[[0.00525873615, -0.999894519, 0.0134620306, 46.5174596], [0.999959617, 0.00535678348, -0.00735796480, 32.0776662], [0.00728773209, -0.0135001806, 0.999882310, -4.24772615], [0.0, 0.0, 0.0, 1.0]]', placeholder='[[0.00525873615, -0.999894519, 0.0134620306, 46.5174596], [0.999959617, 0.00535678348, -0.00735796480, 32.0776662], [0.00728773209, -0.0135001806, 0.999882310, -4.24772615], [0.0, 0.0, 0.0, 1.0]]', description='Camera & Robot Calibration Matrix', disabled=False, layout={'width': '99%'}, style=style),            \n",
    "\n",
    "            \"out_prm\": widgets.Textarea(value='', placeholder='', description='Configuration', disabled=True, layout={'width': '99%'}),\n",
    "            \"out_return\": widgets.Textarea(value='', placeholder='', description='Return value', disabled=True, layout={'width': '99%'}),\n",
    "\n",
    "            \"close\": widgets.Button( description='Terminate App', disabled=False, button_style=\"danger\", tooltip='Terminate App'),\n",
    "\n",
    "        }\n",
    "\n",
    "class App(object):\n",
    "    \"\"\"docstring for App\"\"\"\n",
    "    def __init__(self):\n",
    "        super(App, self).__init__()\n",
    "        self.retval ={}\n",
    "        self.config = {}\n",
    "\n",
    "    def close(self, b):\n",
    "        self.d.close()\n",
    "        self.d.camera.close()\n",
    "        plt.close('all')\n",
    "\n",
    "    def run(self, ip_address, model_path=None, calibration_matrix=None, frame=None):        \n",
    "        # camera\n",
    "        camera_connect = False\n",
    "        camera = Camera()\n",
    "        try:\n",
    "            camera.connect()\n",
    "            camera_connect = True\n",
    "            self.camera_connect = camera_connect\n",
    "        except Exception as ex:\n",
    "            print(ex)\n",
    "            pass\n",
    "        \n",
    "        # detect\n",
    "        self.d = Detection(camera)\n",
    "        \n",
    "        # capture the first \n",
    "        if camera_connect:\n",
    "            self.d.update_camera_data()\n",
    "        else:\n",
    "            self.d.camera_data = {\"depth_frame\": None, \"ir_frame\": None, \"color_frame\": None, \"depth_img\": None, \"ir_img\": None, \"color_img\": np.zeros((10, 10, 3), dtype=np.uint8), \"depth_int\": None, \"frames\": None, \"timestamp\": 0}\n",
    "    \n",
    "        \"\"\"out plot\"\"\"\n",
    "        # close everything first\n",
    "        plt.close('all')\n",
    "        \n",
    "        # Create an initial display with the original image\n",
    "        fig, ax = plt.subplots(frameon=False)\n",
    "        self.plt = {\n",
    "            \"out\":{\n",
    "                \"fig\": fig,\n",
    "                \"ax\": ax,\n",
    "                \"img_plt\": ax.imshow(cv.cvtColor(self.d.camera_data[\"color_img\"], cv.COLOR_BGR2RGB))\n",
    "        }}\n",
    "        #self.plt[\"out\"][\"fig\"].suptitle(\"Output image\")\n",
    "        self.plt[\"out\"][\"fig\"].canvas.header_visible = False\n",
    "        self.plt[\"out\"][\"fig\"].tight_layout()\n",
    "\n",
    "        \n",
    "        \"\"\"widgets\"\"\"\n",
    "        # widget\n",
    "        self.widget_in = default_widget().widget_input\n",
    "        self.widget_tr = default_widget().widget_trigger\n",
    "        \n",
    "        \"\"\"accordion for adjust the image\"\"\"\n",
    "        # adjust_image\n",
    "        color_picker_box = widgets.HBox([self.widget_tr[k] for k in [key for key in self.widget_tr.keys() if key.startswith('color_')]])\n",
    "        acc_adjust_img = widgets.Accordion()\n",
    "        acc_adjust_img.children = [\n",
    "            widgets.VBox([self.widget_in[k] for k in [key for key in self.widget_in.keys() if key.startswith('roi_')]]),\n",
    "            widgets.VBox([self.widget_in[k] for k in [key for key in self.widget_in.keys() if key.startswith('intensity_')]]),\n",
    "            widgets.VBox([self.widget_in[k] for k in [key for key in self.widget_in.keys() if key.startswith('color_')]]+[widgets.HTML(\"<hr>\")]+[color_picker_box]),\n",
    "        ]\n",
    "\n",
    "        for i, title in enumerate(['Region of Interest', 'Intensity', 'Color Mask']):\n",
    "            acc_adjust_img.set_title(i, title)    \n",
    "\n",
    "        \"\"\"source vbox\"\"\"\n",
    "        source_vbox = widgets.VBox([\n",
    "            widgets.HBox([self.widget_tr[k] for k in [key for key in [\"source_value\", \"s_file_value\", \"s_apply\"]]]),\n",
    "            widgets.VBox([widgets.HTML(\"<hr>\")]),\n",
    "            #widgets.HBox([self.widget_tr[k] for k in [key for key in [\"model_path\", \"model_save\"]]]),\n",
    "            #widgets.VBox([widgets.HTML(\"<hr>\")]),\n",
    "            #widgets.HBox([self.widget_tr[k] for k in [key for key in [\"robot_ip\", \"robot_connect\"]]]),\n",
    "            #widgets.HBox([self.widget_tr[k] for k in [key for key in [\"s_save_path\",\"s_save\"]]]),\n",
    "            #widgets.VBox([widgets.HTML(\"<hr>\")]),\n",
    "            #widgets.HBox([self.widget_tr[k] for k in [key for key in [\"camera_robot_calibration\"]]]),\n",
    "            #widgets.VBox([widgets.HTML(\"<hr>\")]),\n",
    "            widgets.HBox([self.widget_tr[k] for k in [key for key in [\"close\"]]]),\n",
    "        ])\n",
    "\n",
    "        \"\"\"method vbox\"\"\"\n",
    "        method_vbox = widgets.VBox([\n",
    "            self.widget_in[\"method_value\"],\n",
    "            widgets.VBox([widgets.HTML(\"<hr>\")]),\n",
    "            widgets.VBox([self.widget_in[k] for k in [key for key in self.widget_in.keys() if key.startswith('m_elp_')]]),\n",
    "            widgets.VBox([self.widget_in[k] for k in [key for key in self.widget_in.keys() if key.startswith('m_circle_')]]),\n",
    "            widgets.VBox([self.widget_in[k] for k in [key for key in self.widget_in.keys() if key.startswith('m_poly_')]]),\n",
    "            widgets.VBox([self.widget_in[k] for k in [key for key in self.widget_in.keys() if key.startswith('m_cnt_')]]),\n",
    "            widgets.VBox([self.widget_in[k] for k in [key for key in self.widget_in.keys() if key.startswith('m_aruco_')]]),\n",
    "            widgets.VBox([self.widget_in[k] for k in [key for key in self.widget_in.keys() if key.startswith('m_ocr_')]]),\n",
    "            widgets.VBox([self.widget_in[k] for k in [key for key in self.widget_in.keys() if key.startswith('m_od_')]]),\n",
    "        ], layout={'width': '100%'})        \n",
    "\n",
    "        \"\"\"POI\"\"\"\n",
    "        # poi selector\n",
    "        poi_plot = widgets.Output()\n",
    "        with poi_plot:\n",
    "            # init fig and ax\n",
    "            fig, ax = self.poi_plt()\n",
    "            self.plt[\"poi\"] = {\n",
    "                \"fig\": fig,\n",
    "                \"ax\": ax\n",
    "            }\n",
    "            plt.show(self.plt[\"poi\"][\"fig\"])  \n",
    "\n",
    "        # init poi\n",
    "        self.poi_value = poly_select(self.widget_in[\"poi_value\"])\n",
    "\n",
    "        # Initialize poi selector\n",
    "        self.poi_selector = PolygonSelector(self.plt[\"poi\"][\"ax\"], onselect=self.poi_value.onselect, useblit=True, props=dict(color='orange', linestyle='--'))\n",
    "        poi_box = widgets.VBox([self.widget_in[\"poi_value\"], poi_plot])\n",
    "\n",
    "\n",
    "        \"\"\"accordion for spatial constraints\"\"\"\n",
    "        # spatial constraints\n",
    "        acc_spatial = widgets.Accordion()\n",
    "        acc_spatial.children = [\n",
    "            widgets.VBox([self.widget_in[k] for k in [key for key in self.widget_in.keys() if key.startswith('2d_range_')]]),\n",
    "            widgets.VBox([self.widget_in[k] for k in [key for key in self.widget_in.keys() if key.startswith('3d_range_')]]),\n",
    "            poi_box,\n",
    "        ]\n",
    "\n",
    "        for i, title in enumerate([\"Size \", 'Location', '6D-Pose']):\n",
    "            acc_spatial.set_title(i, title)    \n",
    "\n",
    "        \"\"\"method plot\"\"\"\n",
    "        method_plt = widgets.Output(layout={'width': '100%'})\n",
    "        with method_plt:\n",
    "            # init fig and ax\n",
    "            fig, ax = plt.subplots(frameon=False)\n",
    "            self.plt[\"method\"] = {\n",
    "                \"fig\": fig,\n",
    "                \"ax\": ax,\n",
    "                \"img_plt\": ax.imshow(self.d.camera_data[\"color_img\"], cmap='gray')\n",
    "            }\n",
    "            self.plt[\"method\"][\"fig\"].canvas.header_visible = False\n",
    "            self.plt[\"method\"][\"fig\"].tight_layout()\n",
    "            self.plt[\"method\"][\"fig\"].set_size_inches((4,3), forward=True)\n",
    "            self.plt[\"method\"][\"img_plt\"].set_visible(False)\n",
    "            self.plt[\"out\"][\"ax\"].axis('off')\n",
    "            plt.show(self.plt[\"method\"][\"fig\"])\n",
    "\n",
    "        \"\"\"result\"\"\"\n",
    "        result_vbox = widgets.VBox([self.widget_tr[k] for k in [key for key in self.widget_tr.keys() if key.startswith('out_')]])\n",
    "\n",
    "        \"\"\"tab\"\"\"\n",
    "        tab = widgets.Tab()\n",
    "        tab.children = [\n",
    "            source_vbox,\n",
    "            acc_adjust_img,\n",
    "            widgets.HBox([method_vbox, method_plt]),\n",
    "            acc_spatial,\n",
    "            result_vbox,\n",
    "        ]\n",
    "        tab.set_title(0, 'Initialization')\n",
    "        tab.set_title(1, 'Visual Adjustment')\n",
    "        tab.set_title(2, 'Detection')\n",
    "        tab.set_title(3, 'OBB')\n",
    "        tab.set_title(4, 'Result')\n",
    "        display(tab)\n",
    "\n",
    "        \"\"\"roi\"\"\"\n",
    "        # init roi\n",
    "        self.roi_value = poly_select(self.widget_in[\"roi_value\"])\n",
    "\n",
    "        # Initialize PolygonSelector\n",
    "        self.roi_selector = PolygonSelector(self.plt[\"out\"][\"ax\"], onselect=self.roi_value.onselect, useblit=True, props=dict(color='blue', linestyle='--'))\n",
    "\n",
    "        # interactive for source\n",
    "        interactive(self.hide_show_source, source_value=self.widget_tr[\"source_value\"])\n",
    "\n",
    "        # interactive color_picker\n",
    "        self.widget_tr[\"color_picker\"].observe(self.hex_to_hsv, names='value')\n",
    "        \n",
    "        # capture\n",
    "        self.widget_tr[\"s_apply\"].on_click(self.capture_camera_data)\n",
    "\n",
    "        # capture\n",
    "        self.widget_tr[\"s_update\"].on_click(self.update_source_list)\n",
    "\n",
    "        # save\n",
    "        self.widget_tr[\"s_save\"].on_click(self.save_as_source)\n",
    "\n",
    "        # close\n",
    "        self.widget_tr[\"close\"].on_click(self.close)\n",
    "\n",
    "        # Create an interactive plot with the slider\n",
    "        interactive(self._detect_pattern, **self.widget_in)\n",
    "        \n",
    "        \n",
    "    def hex_to_hsv(self, change):\n",
    "        # Remove '#' if present\n",
    "        hex_color = change['new'].lstrip('#')\n",
    "\n",
    "        # Convert hex to RGB\n",
    "        rgb_color = tuple(int(hex_color[i:i+2], 16) for i in (0, 2, 4))\n",
    "\n",
    "        # Normalize RGB values to the range [0, 1]\n",
    "        normalized_rgb = tuple(value / 255.0 for value in rgb_color)\n",
    "\n",
    "        # Convert RGB to HSV\n",
    "        hsv_color = colorsys.rgb_to_hsv(*normalized_rgb)\n",
    "\n",
    "        # Adjust HSV values to the common OpenCV conventions\n",
    "        h = int(hsv_color[0] * 179)\n",
    "        s = int(hsv_color[1] * 255)\n",
    "        v = int(hsv_color[2] * 255)\n",
    "        self.widget_tr[\"color_hsv\"].value = f\"Hue = {h}, Saturation = {s}, Value = {v}\"\n",
    "\n",
    "        # color\n",
    "        self.widget_in[\"color_h\"].value = [max(0, h-20), min(179, h+20)]\n",
    "        self.widget_in[\"color_s\"].value = [max(0, s-20), min(255, s+20)]\n",
    "        self.widget_in[\"color_v\"].value = [max(0, v-20), min(255, v+20)]\n",
    "\n",
    "\n",
    "    \n",
    "    def save_as_source(self, b):\n",
    "        file_path = self.widget_tr[\"s_save_path\"].value\n",
    "        \n",
    "        # opencv\n",
    "        cv.imwrite(file_path, self.d.camera_data[\"color_img\"])\n",
    "\n",
    "        \n",
    "    def open_pkl(self, file_path):\n",
    "        with open(file_path, 'rb') as file:\n",
    "            loaded_data = pkl.load(file)\n",
    "        return loaded_data\n",
    "\n",
    "\n",
    "    def capture_camera_data(self, b):\n",
    "        if self.widget_tr[\"source_value\"].value == 1: # read from file\n",
    "            # file_path\n",
    "            file_path = self.widget_tr[\"s_file_value\"].value\n",
    "            \n",
    "            if file_path.endswith(\".pkl\"): # picle format\n",
    "                # data\n",
    "                self.d.camera_data = self.open_pkl(file_path)\n",
    "            else:\n",
    "                img = cv.imread(file_path)\n",
    "                self.d.camera_data = {\"depth_frame\": None, \"ir_frame\": None, \"color_frame\": None, \"depth_img\": None, \"ir_img\": None, \"color_img\": img, \"depth_int\": None, \"frames\": None, \"timestamp\": 0}\n",
    "\n",
    "        elif self.widget_tr[\"source_value\"].value == 0: # d405\n",
    "            # get the data from camera\n",
    "            self.d.update_camera_data()\n",
    "\n",
    "        # adjust the frame size\n",
    "        self.plt[\"out\"][\"img_plt\"].set_extent([0, self.d.camera_data[\"color_img\"].shape[1], self.d.camera_data[\"color_img\"].shape[0], 0])\n",
    "        self.plt[\"method\"][\"img_plt\"].set_extent([0, self.d.camera_data[\"color_img\"].shape[1], self.d.camera_data[\"color_img\"].shape[0], 0])\n",
    "\n",
    "        # call update\n",
    "        kwargs = {k:self.widget_in[k].value for k in self.widget_in.keys()}\n",
    "        self._detect_pattern(**kwargs)     \n",
    "\n",
    "    def update_source_list(self, b):\n",
    "        all_device = self.d.camera.all_device()\n",
    "        \n",
    "        i = 0\n",
    "        options = []\n",
    "        for device in all_device:\n",
    "            options.append((device[\"name\"] +\" (S/N: \"+device[\"serial_number\"], \")\", i))\n",
    "            i += 1\n",
    "        options.append(('Image file', i))\n",
    "        self.widget_tr[\"source_value\"].options = options\n",
    "        \n",
    "    def hide_show_source(self, **kwargs):\n",
    "        if kwargs[\"source_value\"] == 1:\n",
    "            self.widget_tr[\"s_file_value\"].layout.display = \"flex\"\n",
    "        elif kwargs[\"source_value\"] == 0:\n",
    "            self.widget_tr[\"s_file_value\"].layout.display = \"none\"\n",
    "\n",
    "\n",
    "    def poi_plt(self):\n",
    "        # create\n",
    "        fig, ax = plt.subplots(frameon=False)\n",
    "        #fig.suptitle(\"Select 3 points of interest\")\n",
    "        fig.canvas.header_visible = False\n",
    "        fig.tight_layout()\n",
    "        \n",
    "        # Set the height and calculate the width based on the golden ratio\n",
    "        height = 1.0\n",
    "        width = 1.0\n",
    "\n",
    "        # Draw the ellipse in magenta\n",
    "        ellipse = Ellipse((0, 0), 2 * width, 2 * height, linewidth=1, edgecolor='#FF00FF', facecolor='none')\n",
    "        ax.add_patch(ellipse)\n",
    "\n",
    "        # Draw the minimum bounding box around the ellipse in magenta\n",
    "        min_bounding_box = plt.Rectangle((-width, -height), 2 * width, 2 * height, linewidth=1, edgecolor='#FF00FF', facecolor='none', label='Oriented Bounding Box')\n",
    "        ax.add_patch(min_bounding_box)\n",
    "\n",
    "        # Draw major and minor axes\n",
    "        major_axis = plt.Line2D([0, width], [0, 0], color='red', linestyle='dashed', linewidth=1, label='Major Axis')\n",
    "        minor_axis = plt.Line2D([0, 0], [0, height], color='green', linestyle='dashed', linewidth=1, label='Minor Axis')\n",
    "        ax.add_line(major_axis)\n",
    "        ax.add_line(minor_axis)\n",
    "\n",
    "        # Plot the center of the rectangle in blue\n",
    "        ax.plot(0, 0, marker='o', markersize=6, color='blue', label='Center')\n",
    "\n",
    "        # Set axis limits with x and y axes twice as large\n",
    "        ax.set_xlim(-2 * width, 2 * width)\n",
    "        ax.set_ylim(-2 * height, 2 * height)\n",
    "\n",
    "        # Display the legend\n",
    "        ax.legend()\n",
    "\n",
    "        # Set aspect ratio\n",
    "        ax.set_aspect(1/1.68)\n",
    "\n",
    "        # invert y\n",
    "        ax.invert_yaxis()\n",
    "\n",
    "        # Display the plot\n",
    "        return fig, ax\n",
    "\n",
    "    \n",
    "    def _detect_pattern(self, **kwargs):\n",
    "        try:\n",
    "            # adjust kwargs\n",
    "            kwargs[\"roi_value\"] = ast.literal_eval(kwargs[\"roi_value\"])\n",
    "            kwargs[\"poi_value\"] = ast.literal_eval(kwargs[\"poi_value\"])\n",
    "\n",
    "            # adjust kwargs\n",
    "            prm = {}\n",
    "            \"\"\"\n",
    "            #roi\n",
    "            if kwargs[\"roi_enb\"]:\n",
    "                prm.append()\n",
    "            \"\"\"\n",
    "            # run pattern detection\n",
    "            timestamp, retval, adjust_img, thr_img, _ = self.d._pattern(self.d.camera, self.d.camera_data, **kwargs)\n",
    "\n",
    "\n",
    "            \"\"\"hide and show inputs\"\"\"\n",
    "            show_key = [[key for key in self.widget_in.keys() if key.startswith(term)] for term in [\"m_elp\", \"m_circle\", \"m_poly\", \"m_cnt\", \"m_aruco\", \"m_ocr\", \"m_od\"]][kwargs[\"method_value\"]]\n",
    "            hide_key = [key for key in self.widget_in.keys() if key.startswith('m_') and key not in show_key] \n",
    "            self.xxx = show_key\n",
    "            for k in show_key:\n",
    "                if self.widget_in[k].layout.display != \"flex\":\n",
    "                    self.widget_in[k].layout.display = \"flex\"\n",
    "            for k in hide_key:\n",
    "                if self.widget_in[k].layout.display != \"none\":\n",
    "                    self.widget_in[k].layout.display = \"none\"\n",
    "\n",
    "            # display thr\n",
    "            if kwargs[\"method_value\"] in [0, 4, 5, 6]: # ellipse, aruco      \n",
    "                # img\n",
    "                self.plt[\"method\"][\"img_plt\"].set_visible(False)\n",
    "                self.plt[\"method\"][\"ax\"].axis('off')\n",
    "\n",
    "\n",
    "            elif kwargs[\"method_value\"] in [1, 2, 3]: # polygon and contour\n",
    "                # img\n",
    "                self.plt[\"method\"][\"img_plt\"].set_visible(True)\n",
    "                self.plt[\"method\"][\"ax\"].axis('on')\n",
    "                self.plt[\"method\"][\"img_plt\"].set_data(thr_img)\n",
    "\n",
    "\n",
    "            # Update the existing plot\n",
    "            self.plt[\"out\"][\"img_plt\"].set_data(cv.cvtColor(adjust_img, cv.COLOR_BGR2RGB))\n",
    "\n",
    "            # Redraw the plot\n",
    "            self.plt[\"out\"][\"fig\"].canvas.draw_idle()\n",
    "            self.plt[\"method\"][\"fig\"].canvas.draw_idle()\n",
    "\n",
    "            # type retval\n",
    "            json_str = json.dumps(retval)\n",
    "            converted_retval = json.loads(json_str, parse_int=lambda x: int(x), parse_float=lambda x: float(x), parse_constant=lambda x: x, object_hook=lambda d: {k: 1 if v is True else 0 if v is False else v for k, v in d.items()}) \n",
    "            self.widget_tr[\"out_return\"].value = json.dumps(converted_retval)\n",
    "            self.retval = retval\n",
    "\n",
    "            # parameters\n",
    "            json_str = json.dumps(kwargs)\n",
    "            converted_kwargs = json.loads(json_str, parse_int=lambda x: int(x), parse_float=lambda x: float(x), parse_constant=lambda x: x, object_hook=lambda d: {k: 1 if v is True else 0 if v is False else v for k, v in d.items()}) \n",
    "            self.widget_tr[\"out_prm\"].value = json.dumps(converted_kwargs)\n",
    "            self.config = kwargs\n",
    "        except Exception as ex:\n",
    "            print(ex)\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robot_ip_address = \"\"\n",
    "object_detection_model_path = \"\"\n",
    "camera_robot_calibration_matrix = None\n",
    "frame = None\n",
    "x = App()\n",
    "x.run(robot_ip_address, object_detection_model_path, camera_robot_calibration_matrix, frame)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
