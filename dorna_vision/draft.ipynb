{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interactive, widgets\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "from matplotlib.widgets import PolygonSelector\n",
    "from matplotlib.patches import Ellipse\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
    "import json\n",
    "import textwrap\n",
    "import ast\n",
    "import pickle as pkl\n",
    "\n",
    "from camera import Camera\n",
    "from dorna2 import Dorna\n",
    "\n",
    "#from dorna_vision.draw import *\n",
    "from dorna_vision.detect import *\n",
    "from dorna_vision.draw import *\n",
    "from dorna_vision.util import *\n",
    "\n",
    "\n",
    "\n",
    "class default_widget(object):\n",
    "    \"\"\"docstring for ClassName\"\"\"\n",
    "    def __init__(self,):\n",
    "        super(default_widget, self).__init__()\n",
    "        continuous_update = False\n",
    "        style={'description_width': '150px'}\n",
    "        widgets.IntText(value=7, description='Any:', disabled=False)\n",
    "        self.widget_helper = {\n",
    "            \"xyz_label\": widgets.HTML(value=\"Convert pixel coordinates to its 3D spatial values based on the predefined reference frame.\", layout={'width': '99%'}, style=style),\n",
    "            \"xyz_width\": widgets.IntText(value=10, placeholder=10, description='Width (pxl)', disabled=False, style=style),\n",
    "            \"xyz_height\": widgets.IntText(value=10, placeholder=10, description='Height (pxl)', disabled=False, style=style),\n",
    "            \"xyz_xyz\": widgets.Text(value='[0, 0, 0]', placeholder='[0, 0, 0]', description='Result (mm)', disabled=True, style=style),\n",
    "            \"xyz_convert\": widgets.Button( description='Convert', disabled=False, button_style=\"\", tooltip='Convert'),\n",
    "        }\n",
    "\n",
    "        self.widget_init = {\n",
    "            \"camera_setup_label\": widgets.HTML(value=\"<ul><li><strong>Eye-in-hand</strong>: When the camera is mounted on the robot, input the robot's IP address to synchronize the 3D data with the robot.</li><li><strong>Eye-to-hand</strong>: If the camera is stationary, leave the robot's IP address field blank.</li></ul>\", layout={'width': '99%'}, style=style),\n",
    "            \"camera_setup_type\": widgets.Dropdown(value=1, options=[('Eye-in-hand', 0), ('Eye-to-hand', 1),], description='Mounting setup', continuous_update=continuous_update, style=style),\n",
    "            \"camera_setup_robot_ip\": widgets.Text(value='localhost', placeholder='localhost', description='Robot IP address', disabled=False, style=style),\n",
    "            \"frame_label\": widgets.HTML(value=\"Specify the reference frame based on the camera's setup:    <ul> <li>If the camera is attached to the robot (eye-in-hand), set it relative to the robot's base frame.</li> <li>If the camera is fixed (eye-to-hand), set it relative to the camera frame.</li> </ul> All measurements will be reported concerning this selected frame.\", layout={'width': '99%'}, style=style),\n",
    "            \"frame_value\": widgets.Text(value='[0, 0, 0, 0, 0, 0]', placeholder='[0, 0, 0, 0, 0, 0]', description='Frame', disabled=False, style=style),\n",
    "            \"ml_label\": widgets.HTML(value=\"Specify the path to the model, for any ML-based detection method.\", layout={'width': '99%'}, style=style),\n",
    "            \"ml_detection_type\": widgets.Dropdown(value=0, options=[('Object detection', 0), ('Image classification', 1)], description='Detection method', continuous_update=continuous_update, style=style),\n",
    "            \"ml_detection_path\": widgets.Text(value='', placeholder='Path to the detection model file (*.pkl), e.g., ai_models/test.pkl.', description='Model path', disabled=False, layout={'width': '99%'}, style=style),\n",
    "\n",
    "            \"init\": widgets.Button( description='Initialize Parameters', disabled=False, tooltip='Initialize Parameters', button_style=\"success\"), \n",
    "        }\n",
    "        self.widget_input = {\n",
    "            \"plane_label\": widgets.Label(value=\"Choose three points on the oriented bounding box to define a hyperplane and determine the detected item's 6D pose.\", layout={'width': '99%'}, style=style),\n",
    "            \"plane_enb\": widgets.Checkbox(value=False, description='Apply 6D pose', continuous_update=continuous_update, layout={'width': '99%'}, style=style),\n",
    "            \"plane_value\": widgets.Text(value=\"[]\", placeholder='[]', description='Plane', disabled=True, layout={'width': '99%'}, style=style),\n",
    "            \n",
    "            \"color_label\": widgets.Label(value=\"Apply a color mask to filter specific colors by adjusting hue, saturation, and value. Fine-tune these settings to isolate the desired color range for better detection results.\", layout={'width': '99%'}, style=style),\n",
    "            \"color_enb\": widgets.Checkbox(value=False, description='Apply color mask', continuous_update=continuous_update, layout={'width': '99%'}, style=style),\n",
    "            \"color_h\": widgets.IntRangeSlider(value=[60, 120], min=0, max=179, step=1, description='Hue', continuous_update=continuous_update, layout={'width': '99%'}, style=style),\n",
    "            \"color_s\": widgets.IntRangeSlider(value=[85, 170], min=0, max=255, step=1, description='Saturation', continuous_update=continuous_update, layout={'width': '99%'}, style=style),\n",
    "            \"color_v\": widgets.IntRangeSlider(value=[85, 170], min=0, max=255, step=1, description='Vue', continuous_update=continuous_update, layout={'width': '99%'}, style=style),\n",
    "            \"color_inv\": widgets.Checkbox(value=False, description='Invert color mask', continuous_update=continuous_update, layout={'width': '99%'}, style=style),\n",
    "\n",
    "            \"roi_label\": widgets.Label(value=\"Select the region of interest where the detection method is applied. Use the blue polygon selector on the output image to define this area.\", layout={'width': '99%'}, style=style),\n",
    "            \"roi_enb\": widgets.Checkbox(value=False, description='Apply ROI', continuous_update=continuous_update, layout={'width': '99%'}, style=style),\n",
    "            \"roi_value\": widgets.Text(value='[]', placeholder='[]', description='ROI', disabled=True, layout={'width': '99%'}, style=style),\n",
    "            \"roi_inv\": widgets.Checkbox(value=False, description='Invert region', continuous_update=continuous_update, layout={'width': '99%'}, style=style),\n",
    "            \"roi_crop\": widgets.Checkbox(value=False, description='Crop region', continuous_update=continuous_update, layout={'width': '99%'}, style=style),\n",
    "\n",
    "            \"intensity_label\": widgets.Label(value=\"Adjust brightness and contrast if necessary to enhance image details. Use the sliders for optimal visibility and improved detection results.\", layout={'width': '99%'}, style=style),\n",
    "            \"intensity_enb\": widgets.Checkbox(value=False, description='Apply the intensity', continuous_update=continuous_update, layout={'width': '99%'}, style=style),\n",
    "            \"intensity_a\" : widgets.FloatSlider(value=1, min=0, max=4, step=0.01, description='Contrast', continuous_update=continuous_update, layout={'width': '99%'}, style=style),\n",
    "            \"intensity_b\" : widgets.IntSlider(value=0, min=-255, max=255, step=1, description='Brightness', continuous_update=continuous_update, layout={'width': '99%'}, style=style),\n",
    "\n",
    "            \"2d_range_label\": widgets.Label(value=\"Apply 2D constraints on the detected item's oriented bounding box aspect ratio and area to refine detection accuracy.\", layout={'width': '99%'}, style=style),\n",
    "            \"2d_range_enb\": widgets.Checkbox(value=False, description='Apply 2D constraints', continuous_update=continuous_update,layout={'width': '99%'}, style=style),\n",
    "            \"2d_range_aspect_ratio\": widgets.FloatRangeSlider(value=[0, 1], min=0, max=1, step=0.01, description='Aspect ratio', continuous_update=continuous_update, layout={'width': '99%'}, style=style),\n",
    "            \"2d_range_area_range\": widgets.IntRangeSlider(value=[0, 100000], min=0, max=100000, step=100, description='Area (pxl X pxl)', continuous_update=continuous_update, layout={'width': '99%'}, style=style),\n",
    "\n",
    "            \"3d_range_label\": widgets.Label(value=\"Apply 3D constraints to remove detected items outside the specified x, y, z range relative to the frame.\", layout={'width': '99%'}, style=style),\n",
    "            \"3d_range_enb\": widgets.Checkbox(value=False, description='Apply 3D constraints', continuous_update=continuous_update, layout={'width': '99%'}, style=style),\n",
    "            \"3d_range_x\": widgets.IntRangeSlider(value=[250, 350], min=-1000, max=1000, step=1, description='x (mm)', continuous_update=continuous_update, layout={'width': '99%'}, style=style),\n",
    "            \"3d_range_y\": widgets.IntRangeSlider(value=[0, 50], min=-1000, max=1000, step=1, description='y (mm)', continuous_update=continuous_update, layout={'width': '99%'}, style=style),\n",
    "            \"3d_range_z\": widgets.IntRangeSlider(value=[0, 50], min=-1000, max=1000, step=1, description='z (mm)', continuous_update=continuous_update, layout={'width': '99%'}, style=style),\n",
    "            \"3d_range_inv\": widgets.Checkbox(value=False, description='Invert the range', continuous_update=continuous_update, layout={'width': '99%'}, style=style),\n",
    "\n",
    "            \"method_value\": widgets.Dropdown(value=0, options=[('No detection', 0), ('Ellipse detection', 1), ('Polygon detection', 2), ('Contour detection', 3), ('Aruco detection', 4), ('OCR detection', 5)], description='Detection method', continuous_update=continuous_update, style=style),\n",
    "    \n",
    "            \"m_elp_pf_mode\": widgets.Checkbox(value=False, description='Auto detection', continuous_update=continuous_update,layout={'width': '99%'}, style=style),\n",
    "            \"m_elp_nfa_validation\": widgets.Checkbox(value=True, description='False alarm validation', continuous_update=continuous_update, layout={'width': '99%'}, style=style),\n",
    "            \"m_elp_min_path_length\": widgets.IntSlider(value=50, min=1, max=1000, step=1, description='Min path length', continuous_update=continuous_update, layout={'width': '99%'}, style=style),\n",
    "            \"m_elp_min_line_length\": widgets.IntSlider(value=10, min=1, max=1000, step=1, description='Min line length', continuous_update=continuous_update, layout={'width': '99%'}, style=style),\n",
    "            \"m_elp_sigma\": widgets.IntSlider(value=1, min=0, max=20, step=0.1, description='Blur', continuous_update=continuous_update, layout={'width': '99%'}, style=style),\n",
    "            \"m_elp_gradient_threshold_value\": widgets.IntSlider(value=20, min=1, max=100, step=1, description='Gradient', continuous_update=continuous_update, layout={'width': '99%'}, style=style),\n",
    "    \n",
    "\n",
    "            \"m_poly_inv\": widgets.Checkbox(value=True, description='Inverse', continuous_update=continuous_update, layout={'width': '99%'}, style=style),\n",
    "            \"m_poly_type\": widgets.Dropdown(value=0, options=[('0: Otsu (auto)', 0), ('1: Binary', 1), ('2: Gaussian', 2)], description='Type', continuous_update=continuous_update, layout={'width': '99%'}, style=style),\n",
    "            \"m_poly_thr\" : widgets.IntSlider(value=127, min=0, max=255, step=1, description='Threshold value', continuous_update=continuous_update, layout={'width': '99%'}, style=style),\n",
    "            \"m_poly_blur\": widgets.IntSlider(value=3, min=1, max=20, step=1, description='Smoothing blur', continuous_update=continuous_update, layout={'width': '99%'}, style=style),                    \n",
    "            \"m_poly_mean_sub\": widgets.IntSlider(value=0, min=-200, max=200, step=1, description='Mean subtract', continuous_update=continuous_update, layout={'width': '99%'}, style=style),\n",
    "            \"m_poly_side\" : widgets.IntSlider(value=3, min=3, max=20, step=1, description='Sides', continuous_update=continuous_update, layout={'width': '99%'}, style=style),\n",
    "\n",
    "            \n",
    "            \"m_cnt_inv\": widgets.Checkbox(value=True, description='Inverse', continuous_update=continuous_update, layout={'width': '99%'}, style=style),\n",
    "            \"m_cnt_type\": widgets.Dropdown(value=0, options=[('0: Otsu (auto)', 0), ('1: Binary', 1), ('2: Gaussian', 2)], description='Type', continuous_update=continuous_update, layout={'width': '99%'}, style=style),\n",
    "            \"m_cnt_thr\" : widgets.IntSlider(value=127, min=0, max=255, step=1, description='Threshold value', continuous_update=continuous_update, layout={'width': '99%'}, style=style),\n",
    "            \"m_cnt_blur\": widgets.IntSlider(value=3, min=1, max=20, step=1, description='Smoothing blur', continuous_update=continuous_update, layout={'width': '99%'}, style=style),                    \n",
    "            \"m_cnt_mean_sub\": widgets.IntSlider(value=0, min=-200, max=200, step=1, description='Mean subtract', continuous_update=continuous_update, layout={'width': '99%'}, style=style),\n",
    "\n",
    "            \"m_aruco_dictionary\":widgets.Dropdown(value=\"DICT_6X6_250\", options= [\"DICT_4X4_50\", \"DICT_4X4_100\", \"DICT_4X4_250\", \"DICT_4X4_1000\", \"DICT_5X5_50\", \"DICT_5X5_100\", \"DICT_5X5_250\", \"DICT_5X5_1000\", \"DICT_6X6_50\", \"DICT_6X6_100\", \"DICT_6X6_250\", \"DICT_6X6_1000\", \"DICT_7X7_50\", \"DICT_7X7_100\", \"DICT_7X7_250\", \"DICT_7X7_1000\", \"DICT_ARUCO_ORIGINAL\", \"DICT_APRILTAG_16h5\", \"DICT_APRILTAG_25h9\", \"DICT_APRILTAG_36h10\", \"DICT_APRILTAG_36h11\"], description='Dictionary', continuous_update=continuous_update, layout={'width': '99%'}, style=style),\n",
    "            \"m_aruco_marker_length\": widgets.FloatSlider(value=10, min=1, max=100, step=0.1, description='Marker length (mm)', continuous_update=continuous_update, layout={'width': '99%'}, style=style),\n",
    "            \"m_aruco_refine\":widgets.Dropdown(value=\"CORNER_REFINE_APRILTAG\", options=[\"CORNER_REFINE_NONE\", \"CORNER_REFINE_SUBPIX\", \"CORNER_REFINE_CONTOUR\", \"CORNER_REFINE_APRILTAG\"], description='Refinement', continuous_update=continuous_update, layout={'width': '99%'}, style=style),\n",
    "            \"m_aruco_subpix\": widgets.Checkbox(value=False, description='Sub pixel', continuous_update=continuous_update, layout={'width': '99%'}, style=style),            \n",
    "\n",
    "            \"m_ocr_conf\" : widgets.FloatSlider(value=0.5, min=0.01, max=1, step=0.01, description='Confidence', continuous_update=continuous_update, layout={'width': '99%'}, style=style), \n",
    "\n",
    "            \"m_od_conf\" : widgets.FloatSlider(value=0.5, min=0.01, max=1, step=0.01, description='Confidence', continuous_update=continuous_update, layout={'width': '99%'}, style=style), \n",
    "            \"m_od_cls\" : widgets.Text(value=\"\", placeholder='', description='Detection classes', disabled=False, layout={'width': '99%'}, style=style), \n",
    "\n",
    "            \"m_cls_conf\" : widgets.FloatSlider(value=0.5, min=0.01, max=1, step=0.01, description='Confidence', continuous_update=continuous_update, layout={'width': '99%'}, style=style), \n",
    "\n",
    "            \"output_label\": widgets.Label(value=\"Choose the maximum number of elements to detect per inference round, enable data shuffling if desired, and save the inference image.\", layout={'width': '99%'}, style=style),\n",
    "            \"output_enb\": widgets.Checkbox(value=False, description='Apply formatting', continuous_update=continuous_update, layout={'width': '99%'}, style=style),\n",
    "            \"output_max_det\" : widgets.IntSlider(value=10, min=1, max=100, step=1, description='Max detections per run', continuous_update=continuous_update, layout={'width': '99%'}, style=style), \n",
    "            \"output_shuffle\": widgets.Checkbox(value=True, description='Shuffle return data', continuous_update=continuous_update, layout={'width': '99%'}, style=style),\n",
    "            \"output_save\": widgets.Checkbox(value=False, description='Save the annotated image in the \"output/*.jpg\"', continuous_update=continuous_update, layout={'width': '99%'}, style=style),\n",
    "            \"output_save_roi\": widgets.Checkbox(value=False, description='Save the annotated ROI image in the \"output/*.jpg\"', continuous_update=continuous_update, layout={'width': '99%'}, style=style),\n",
    "\n",
    "        }\n",
    "        self.widget_trigger = {\n",
    "            \"color_picker\": widgets.ColorPicker(concise=False, description='Color picker', value='blue', disabled=False, style={'text_width': '0'}),\n",
    "            \"color_hsv\": widgets.Text(value='Hue = 119, Saturation = 255, Value = 255', placeholder='', description='', disabled=True,),            \n",
    "\n",
    "            \"source_value\": widgets.Dropdown(value=0, options=[('Stereo camera', 0), ('File', 1)], description='Image source', continuous_update=continuous_update, style=style),\n",
    "            \"source_feed\": widgets.Dropdown(value=\"color_img\", options=[('Color image', \"color_img\")], description='Feed', continuous_update=continuous_update, style=style, layout={'visible': 'none'}),\n",
    "\n",
    "            \"s_file_value\": widgets.Text(value='', placeholder='Path to the file (*.jpg, *.jpeg, *.png, *.tiff, ...).Ex: img/test.jpg', description='File path', disabled=False, layout={'width': '99%'}, style=style),            \n",
    "            \"s_apply\": widgets.Button( description='Capture Image', disabled=True, button_style=\"success\", tooltip='Capture Image', style=style),\n",
    "            #\"s_update\": widgets.Button( description='', disabled=False, button_style=\"\", tooltip='Update source list', icon='refresh', layout={'width': '50px'}),\n",
    "            \"s_save_path\": widgets.Text(value='', placeholder='*.jpg', description='Save image as', disabled=False, layout={'width': '99%'}),            \n",
    "            \"s_save\": widgets.Button( description='Save', disabled=False, button_style=\"\", tooltip='Save as'),\n",
    "\n",
    "            #\"model_path\": widgets.Text(value='', placeholder='/full_path/to_the/object_detection_model.pkl', description='Object Detection Model', disabled=False, layout={'width': '99%'}, style=style),            \n",
    "            #\"model_save\": widgets.Button( description='Set', disabled=False, button_style=\"\", tooltip='Set'),\n",
    "\n",
    "            #\"robot_ip\": widgets.Text(value='', placeholder='192.168.254.10', description='Robot IP Address', disabled=False, layout={'width': '99%'}, style=style),            \n",
    "            #\"robot_connect\": widgets.Button( description='Connect', disabled=False, button_style=\"\", tooltip='Connect'),\n",
    "\n",
    "            #\"camera_robot_calibration\": widgets.Textarea(value='[[0.00525873615, -0.999894519, 0.0134620306, 46.5174596], [0.999959617, 0.00535678348, -0.00735796480, 32.0776662], [0.00728773209, -0.0135001806, 0.999882310, -4.24772615], [0.0, 0.0, 0.0, 1.0]]', placeholder='[[0.00525873615, -0.999894519, 0.0134620306, 46.5174596], [0.999959617, 0.00535678348, -0.00735796480, 32.0776662], [0.00728773209, -0.0135001806, 0.999882310, -4.24772615], [0.0, 0.0, 0.0, 1.0]]', description='Camera & Robot Calibration Matrix', disabled=False, layout={'width': '99%'}, style=style),            \n",
    "            \n",
    "            \"out_prm_label\": widgets.HTML(value=\"API call\", layout={'width': '99%'}, style=style),\n",
    "            \"out_prm\": widgets.Textarea(value='', placeholder='',disabled=True,  rows=15, layout={'width': '99%'}),\n",
    "            \n",
    "            \"out_return_label\": widgets.HTML(value=\"Return value\", layout={'width': '99%'}, style=style),\n",
    "            \"out_return\": widgets.Textarea(value='', placeholder='', disabled=True, rows=5, layout={'width': '99%'}),\n",
    "\n",
    "            \"close\": widgets.Button( description='Exit App', disabled=False, button_style=\"danger\", tooltip='Exit App', layout={'justify-content': 'flex-end'}),\n",
    "        }\n",
    "\n",
    "class Detection_app(object):\n",
    "    \"\"\"docstring for App\"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Detection_app, self).__init__()\n",
    "        self.retval ={}\n",
    "        self.config = {}\n",
    "\n",
    "        \"\"\"widgets\"\"\"\n",
    "        # widget\n",
    "        self.widget_init = default_widget().widget_init\n",
    "        self.widget_in = default_widget().widget_input\n",
    "        self.widget_tr = default_widget().widget_trigger\n",
    "        self.widget_helper = default_widget().widget_helper\n",
    "\n",
    "        # create plots\n",
    "        plt.close('all')\n",
    "        self.plt = {\"out\":{\"fig\":None, \"ax\":None, \"img\":None}, \"method\":{\"fig\":None, \"ax\":None, \"img\":None}, \"plane\":{\"fig\":None, \"ax\":None, \"img\":None}}\n",
    "\n",
    "        \"\"\"plots\"\"\"\n",
    "        # out\n",
    "        self.plt_out = widgets.Output()\n",
    "        with self.plt_out:\n",
    "            self.plt[\"out\"][\"fig\"], self.plt[\"out\"][\"ax\"] = plt.subplots(frameon=False)\n",
    "            self.plt[\"out\"][\"img\"] = self.plt[\"out\"][\"ax\"].imshow(cv.cvtColor(np.zeros((5, 9), dtype=np.uint8), cv.COLOR_BGR2RGB))\n",
    "            self.plt[\"out\"][\"fig\"].canvas.header_visible = False\n",
    "            self.plt[\"out\"][\"fig\"].tight_layout()\n",
    "            self.plt[\"out\"][\"ax\"].axis('off')\n",
    "            plt.show()\n",
    "        self.plt_out.layout.display = \"none\" \n",
    "\n",
    "        # method\n",
    "        self.plt_method = widgets.Output()\n",
    "        with self.plt_method:\n",
    "            self.plt[\"method\"][\"fig\"], self.plt[\"method\"][\"ax\"] = plt.subplots(frameon=False)\n",
    "            self.plt[\"method\"][\"img\"] = self.plt[\"method\"][\"ax\"].imshow(np.zeros((5, 9), dtype=np.uint8))\n",
    "            self.plt[\"method\"][\"fig\"].canvas.header_visible = False\n",
    "            self.plt[\"method\"][\"fig\"].tight_layout()\n",
    "            self.plt[\"method\"][\"fig\"].set_size_inches((4.5, 2.5), forward=True)\n",
    "            self.plt[\"method\"][\"ax\"].axis('off')\n",
    "            plt.show()\n",
    "        self.plt_method.layout.visibility = \"hidden\"\n",
    "        \n",
    "        # plane\n",
    "        self.plt_plane = widgets.Output()\n",
    "        with self.plt_plane:\n",
    "            # init fig and ax\n",
    "            self.plane_plt_maker()\n",
    "            plt.show()  \n",
    "            # init plane\n",
    "            self.plane_value = poly_select(self.widget_in[\"plane_value\"])\n",
    "            # Initialize plane selector\n",
    "            self.plane_selector = PolygonSelector(self.plt[\"plane\"][\"ax\"], onselect=self.plane_value.onselect, useblit=True, props=dict(color='orange', linestyle='--'))\n",
    "        \n",
    "        \"\"\"accordion for adjust the image\"\"\"\n",
    "        # adjust_image\n",
    "        color_picker_box = widgets.HBox([self.widget_tr[k] for k in [key for key in self.widget_tr.keys() if key.startswith('color_')]])\n",
    "        acc_adjust_img = widgets.Accordion()\n",
    "        acc_adjust_img.children = [\n",
    "            widgets.VBox([self.widget_tr[\"source_value\"], self.widget_tr[\"s_file_value\"]]),\n",
    "            widgets.VBox([self.widget_in[k] for k in [key for key in self.widget_in.keys() if key.startswith('roi_')]]),\n",
    "            widgets.VBox([self.widget_in[k] for k in [key for key in self.widget_in.keys() if key.startswith('intensity_')]]),\n",
    "            widgets.VBox([self.widget_in[k] for k in [key for key in self.widget_in.keys() if key.startswith('color_')]]+[widgets.HTML(\"<hr>\")]+[color_picker_box]),\n",
    "        ]\n",
    "        for i, title in enumerate(['Source', 'Region of Interest', 'Intensity', 'Color Mask']):\n",
    "            acc_adjust_img.set_title(i, title)    \n",
    "\n",
    "        \"\"\"init vbox\"\"\"\n",
    "        acc_init_vbox = widgets.Accordion()\n",
    "        acc_init_vbox.children = [\n",
    "            widgets.VBox([self.widget_init[k] for k in [key for key in self.widget_init.keys() if key.startswith('camera_setup_')]]),\n",
    "            widgets.VBox([self.widget_init[k] for k in [key for key in self.widget_init.keys() if key.startswith('frame_')]]),\n",
    "            widgets.VBox([self.widget_init[k] for k in [key for key in self.widget_init.keys() if key.startswith('ml_')]]),\n",
    "        ] \n",
    "        for i, title in enumerate(['1. Camera Mounting', '2. Frame', '3. AI Models']):\n",
    "            acc_init_vbox.set_title(i, title)\n",
    "        \n",
    "        init_vbox = widgets.VBox([\n",
    "            acc_init_vbox,\n",
    "            widgets.HBox([self.widget_init[k] for k in [key for key in [\"init\"]]]),\n",
    "        ])  \n",
    "\n",
    "\n",
    "        \"\"\"method vbox\"\"\"\n",
    "        method_vbox = widgets.VBox([\n",
    "            self.widget_in[\"method_value\"],\n",
    "            widgets.VBox([widgets.HTML(\"<hr>\")]),\n",
    "            widgets.VBox([self.widget_in[k] for k in [key for key in self.widget_in.keys() if key.startswith('m_elp_')]]),\n",
    "            widgets.VBox([self.widget_in[k] for k in [key for key in self.widget_in.keys() if key.startswith('m_poly_')]]),\n",
    "            widgets.VBox([self.widget_in[k] for k in [key for key in self.widget_in.keys() if key.startswith('m_cnt_')]]),\n",
    "            widgets.VBox([self.widget_in[k] for k in [key for key in self.widget_in.keys() if key.startswith('m_aruco_')]]),\n",
    "            widgets.VBox([self.widget_in[k] for k in [key for key in self.widget_in.keys() if key.startswith('m_ocr_')]]),\n",
    "            widgets.VBox([self.widget_in[k] for k in [key for key in self.widget_in.keys() if key.startswith('m_od_')]]),\n",
    "            widgets.VBox([self.widget_in[k] for k in [key for key in self.widget_in.keys() if key.startswith('m_cls_')]]),\n",
    "        ], layout={'width': '100%'})        \n",
    "\n",
    "        \"\"\"accordion for settings\"\"\"\n",
    "        # acc setting\n",
    "        acc_helper = widgets.Accordion()\n",
    "\n",
    "        acc_helper.children = [\n",
    "            widgets.VBox([self.widget_helper[k] for k in [key for key in self.widget_helper.keys() if key.startswith('xyz_')]]),\n",
    "        ]\n",
    "\n",
    "        for i, title in enumerate([\"Pixel to XYZ\"]):\n",
    "            acc_helper.set_title(i, title)  \n",
    "\n",
    "        \"\"\"accordion for settings\"\"\"\n",
    "        # acc setting\n",
    "        acc_setting = widgets.Accordion()\n",
    "        acc_setting.children = [\n",
    "            widgets.VBox([self.widget_in[k] for k in [key for key in self.widget_in.keys() if key.startswith('2d_range_')]]),\n",
    "            widgets.VBox([self.widget_in[k] for k in [key for key in self.widget_in.keys() if key.startswith('3d_range_')]]),\n",
    "            widgets.VBox([self.widget_in[k] for k in [key for key in self.widget_in.keys() if key.startswith('plane_')]]+ [self.plt_plane]),\n",
    "            widgets.VBox([self.widget_in[k] for k in [key for key in self.widget_in.keys() if key.startswith('output_')]]),\n",
    "        ]\n",
    "\n",
    "        for i, title in enumerate([\"2D Limit \", \"3D Limit\", \"6D Pose\", \"Output Format\"]):\n",
    "            acc_setting.set_title(i, title)    \n",
    "\n",
    "\n",
    "        \"\"\"result\"\"\"\n",
    "        result_vbox = widgets.VBox([self.widget_tr[k] for k in [key for key in self.widget_tr.keys() if key.startswith('out_')]])\n",
    "\n",
    "        \"\"\"tab\"\"\"\n",
    "        tabs = [\n",
    "            init_vbox,\n",
    "            acc_adjust_img,\n",
    "            widgets.HBox([method_vbox, self.plt_method]),\n",
    "            acc_setting,\n",
    "            result_vbox,\n",
    "            acc_helper,\n",
    "        ]\n",
    "        self.tab = widgets.Tab()\n",
    "        self.tab.children = tabs\n",
    "\n",
    "        # hide\n",
    "        for i in range(1, len(self.tab.children)):\n",
    "            self.tab.children[i].layout.display = 'none'\n",
    "        \n",
    "        self.tab.set_title(0, 'Initialization')\n",
    "        self.tab.set_title(1, 'Image')\n",
    "        self.tab.set_title(2, 'Detection')\n",
    "        self.tab.set_title(3, 'Setting')\n",
    "        self.tab.set_title(4, 'Result')\n",
    "        self.tab.set_title(5, 'Helper Functions')\n",
    "        \n",
    "        # header\n",
    "        header = widgets.HBox([\n",
    "            self.widget_tr[\"s_apply\"],\n",
    "            self.widget_tr[\"close\"],\n",
    "        ])\n",
    "\n",
    "        # display\n",
    "        display(widgets.VBox([header, self.tab, self.plt_out]))\n",
    "        \n",
    "        # init parameters\n",
    "        self.widget_init[\"init\"].on_click(self.init_parameter)\n",
    "\n",
    "\n",
    "        \"\"\"roi\"\"\"\n",
    "        # init roi\n",
    "        self.roi_value = poly_select(self.widget_in[\"roi_value\"])\n",
    "\n",
    "        # Initialize PolygonSelector\n",
    "        self.roi_selector = PolygonSelector(self.plt[\"out\"][\"ax\"], onselect=self.roi_value.onselect, useblit=True, props=dict(color='blue', linestyle='--'))\n",
    "\n",
    "        # interactive for source\n",
    "        interactive(self.hide_show_source, source_value=self.widget_tr[\"source_value\"])\n",
    "\n",
    "        # interactive for ip\n",
    "        interactive(self.hide_show_ip, source_value=self.widget_init[\"camera_setup_type\"])\n",
    "\n",
    "        # interactive color_picker\n",
    "        self.widget_tr[\"color_picker\"].observe(self.hex_to_hsv, names='value')\n",
    "        \n",
    "        # capture\n",
    "        self.widget_tr[\"s_apply\"].on_click(self.capture_camera_data)\n",
    "\n",
    "        # capture\n",
    "        #self.widget_tr[\"s_update\"].on_click(self.update_source_list)\n",
    "\n",
    "        # save\n",
    "        self.widget_tr[\"s_save\"].on_click(self.save_as_source)\n",
    "\n",
    "        # close\n",
    "        self.widget_tr[\"close\"].on_click(self.__del__)\n",
    "\n",
    "        # pixel to xyz\n",
    "        self.widget_helper[\"xyz_convert\"].on_click(self.pixel_to_xyz)\n",
    "\n",
    "\n",
    "\n",
    "    def __del__(self, b):\n",
    "        # buttons\n",
    "        self.widget_tr[\"close\"].layout.display = \"none\"\n",
    "        self.widget_tr[\"s_apply\"].layout.display = \"none\"\n",
    "\n",
    "        try:\n",
    "            self.d.camera.close()\n",
    "        except Exception as ex:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            self.d.close()\n",
    "        except Exception as ex:\n",
    "            pass\n",
    "        \n",
    "        # plot\n",
    "        plt.close('all')\n",
    "\n",
    "        # tabs\n",
    "        self.tab.close()\n",
    "\n",
    "\n",
    "    def init_parameter(self, b):\n",
    "        # disable elements in init tab\n",
    "        for k in self.widget_init.keys():\n",
    "            self.widget_init[k].disabled = True\n",
    "        self.widget_init[\"init\"].layout.display = 'none'\n",
    "\n",
    "        # data\n",
    "        self.data = None\n",
    "        \n",
    "        # robot\n",
    "        robot = None\n",
    "        if self.widget_init[\"camera_setup_type\"].value == 0:\n",
    "            try:\n",
    "                robot_tmp = Dorna()\n",
    "                if robot_tmp.connect(self.widget_init[\"camera_setup_robot_ip\"].value):\n",
    "                    robot = robot_tmp\n",
    "            except Exception as ex:\n",
    "                print(\"aliali1: \", ex)\n",
    "        \n",
    "        # frame\n",
    "        try:\n",
    "            frame = ast.literal_eval(self.widget_init[\"frame_value\"].value)\n",
    "            if len(frame) != 6:\n",
    "                frame = [0, 0, 0, 0, 0, 0]\n",
    "        except Exception as ex:\n",
    "            frame = [0, 0, 0, 0, 0, 0]\n",
    "\n",
    "        # camera\n",
    "        camera = Camera()\n",
    "        try:\n",
    "            camera.connect()\n",
    "        except Exception as ex:\n",
    "            print(\"aliali1: \", ex)\n",
    "            pass\n",
    "        \n",
    "        # detect\n",
    "        self.d = Detection(camera=camera, robot=robot, frame=frame)\n",
    "        \n",
    "        # ocr\n",
    "        self.d.init_ocr()\n",
    "        \n",
    "        # object_detection\n",
    "        ml_detection_path = self.widget_init[\"ml_detection_path\"].value\n",
    "        if ml_detection_path:\n",
    "            if self.widget_init[\"ml_detection_type\"].value == 0:\n",
    "                self.d.init_od(ml_detection_path) \n",
    "                self.widget_in[\"method_value\"].options = list(self.widget_in[\"method_value\"].options) + [(\"Object detection\", 6)]\n",
    "            elif self.widget_init[\"ml_detection_type\"].value == 1:\n",
    "                self.d.init_cls(ml_detection_path) \n",
    "                self.widget_in[\"method_value\"].options = list(self.widget_in[\"method_value\"].options) + [(\"Image classification\", 7)]\n",
    "\n",
    "        # hide element in method\n",
    "        for k in [key for key in self.widget_in.keys() if key.startswith('m_')]:\n",
    "            self.widget_in[k].layout.display = 'none'\n",
    "\n",
    "        # enable capture image\n",
    "        self.widget_tr[\"s_apply\"].disabled = False\n",
    "\n",
    "        # show tabs\n",
    "        for i in range(1, len(self.tab.children)):\n",
    "            self.tab.children[i].layout.display = \"flex\"\n",
    "\n",
    "        # interactive run with no changing data\n",
    "        interactive(self._detect_pattern, **self.widget_in)\n",
    "\n",
    "        # display plot\n",
    "        #self.plt[\"out\"][\"img\"].set_visible(True)\n",
    "        self.plt_out.layout.display = \"flex\"\n",
    "\n",
    "\n",
    "\n",
    "    def hex_to_hsv(self, change):\n",
    "        # Remove '#' if present\n",
    "        hex_color = change['new'].lstrip('#')\n",
    "\n",
    "        # Convert hex to RGB\n",
    "        rgb_color = tuple(int(hex_color[i:i+2], 16) for i in (0, 2, 4))\n",
    "\n",
    "        # Normalize RGB values to the range [0, 1]\n",
    "        normalized_rgb = tuple(value / 255.0 for value in rgb_color)\n",
    "\n",
    "        # Convert RGB to HSV\n",
    "        hsv_color = colorsys.rgb_to_hsv(*normalized_rgb)\n",
    "\n",
    "        # Adjust HSV values to the common OpenCV conventions\n",
    "        h = int(hsv_color[0] * 179)\n",
    "        s = int(hsv_color[1] * 255)\n",
    "        v = int(hsv_color[2] * 255)\n",
    "        self.widget_tr[\"color_hsv\"].value = f\"Hue = {h}, Saturation = {s}, Value = {v}\"\n",
    "\n",
    "        # color\n",
    "        self.widget_in[\"color_h\"].value = [max(0, h-20), min(179, h+20)]\n",
    "        self.widget_in[\"color_s\"].value = [max(0, s-20), min(255, s+20)]\n",
    "        self.widget_in[\"color_v\"].value = [max(0, v-20), min(255, v+20)]\n",
    "\n",
    "    \n",
    "    def save_as_source(self, b):\n",
    "        file_path = self.widget_tr[\"s_save_path\"].value\n",
    "        \n",
    "        # opencv\n",
    "        cv.imwrite(file_path, self.d.camera_data[\"color_img\"])\n",
    "\n",
    "        \n",
    "    def open_pkl(self, file_path):\n",
    "        with open(file_path, 'rb') as file:\n",
    "            loaded_data = pkl.load(file)\n",
    "        return loaded_data\n",
    "\n",
    "\n",
    "    def pixel_to_xyz(self, b):\n",
    "        width = self.widget_helper[\"xyz_width\"].value\n",
    "        height = self.widget_helper[\"xyz_height\"].value\n",
    "        xyz = self.d.pixel_to_xyz([width, height])\n",
    "        self.widget_helper[\"xyz_xyz\"].value = f\"[{', '.join(f'{value:.1f}' for value in xyz)}]\"\n",
    "\n",
    "\n",
    "    def capture_camera_data(self, b):\n",
    "        self.data = None\n",
    "        if self.widget_tr[\"source_value\"].value == 1: # read from file\n",
    "            # file_path\n",
    "            self.data = self.widget_tr[\"s_file_value\"].value\n",
    "\n",
    "        # call detect pattern\n",
    "        kwargs = {k:self.widget_in[k].value for k in self.widget_in.keys()}\n",
    "        self._detect_pattern(**kwargs)\n",
    "\n",
    "\n",
    "    def update_source_list(self, b):\n",
    "        all_device = self.d.camera.all_device()\n",
    "        \n",
    "        i = 0\n",
    "        options = []\n",
    "        for device in all_device:\n",
    "            options.append((device[\"name\"] +\" (S/N: \"+device[\"serial_number\"], \")\", i))\n",
    "            i += 1\n",
    "        options.append(('Image file', i))\n",
    "        self.widget_tr[\"source_value\"].options = options\n",
    "\n",
    "\n",
    "    def hide_show_source(self, **kwargs):\n",
    "        if kwargs[\"source_value\"] == 1:\n",
    "            self.widget_tr[\"s_file_value\"].layout.display = \"flex\"\n",
    "            #self.widget_tr[\"source_feed\"].layout.display = \"none\"\n",
    "        elif kwargs[\"source_value\"] == 0:\n",
    "            self.widget_tr[\"s_file_value\"].layout.display = \"none\"\n",
    "            #self.widget_tr[\"source_feed\"].layout.display = \"flex\"\n",
    "\n",
    "\n",
    "    def hide_show_ip(self, **kwargs):\n",
    "        if kwargs[\"source_value\"] == 0:\n",
    "            self.widget_init[\"camera_setup_robot_ip\"].layout.display = \"flex\"\n",
    "        elif kwargs[\"source_value\"] == 1:\n",
    "            self.widget_init[\"camera_setup_robot_ip\"].layout.display = \"none\"\n",
    "\n",
    "\n",
    "    def plane_plt_maker(self):\n",
    "        # create\n",
    "        self.plt[\"plane\"][\"fig\"], self.plt[\"plane\"][\"ax\"] = plt.subplots(frameon=False)\n",
    "        #fig.suptitle(\"Select 3 points of interest\")\n",
    "        self.plt[\"plane\"][\"fig\"].canvas.header_visible = False\n",
    "        self.plt[\"plane\"][\"fig\"].tight_layout()\n",
    "        \n",
    "        # Set the height and calculate the width based on the golden ratio\n",
    "        height = 1.0\n",
    "        width = 1.0\n",
    "\n",
    "        # Draw the ellipse in magenta\n",
    "        ellipse = Ellipse((0, 0), 2 * width, 2 * height, linewidth=1, edgecolor='#FF00FF', facecolor='none')\n",
    "        self.plt[\"plane\"][\"ax\"].add_patch(ellipse)\n",
    "\n",
    "        # Draw the minimum bounding box around the ellipse in magenta\n",
    "        min_bounding_box = plt.Rectangle((-width, -height), 2 * width, 2 * height, linewidth=1, edgecolor='#FF00FF', facecolor='none', label='Oriented Bounding Box')\n",
    "        self.plt[\"plane\"][\"ax\"].add_patch(min_bounding_box)\n",
    "\n",
    "        # Draw major and minor axes\n",
    "        major_axis = plt.Line2D([0, width], [0, 0], color='red', linestyle='dashed', linewidth=1, label='Major Axis')\n",
    "        minor_axis = plt.Line2D([0, 0], [0, height], color='green', linestyle='dashed', linewidth=1, label='Minor Axis')\n",
    "        self.plt[\"plane\"][\"ax\"].add_line(major_axis)\n",
    "        self.plt[\"plane\"][\"ax\"].add_line(minor_axis)\n",
    "\n",
    "        # Plot the center of the rectangle in blue\n",
    "        self.plt[\"plane\"][\"ax\"].plot(0, 0, marker='o', markersize=6, color='blue', label='Center')\n",
    "\n",
    "        # Set axis limits with x and y axes twice as large\n",
    "        self.plt[\"plane\"][\"ax\"].set_xlim(-2 * width, 2 * width)\n",
    "        self.plt[\"plane\"][\"ax\"].set_ylim(-2 * height, 2 * height)\n",
    "\n",
    "        # Display the legend\n",
    "        self.plt[\"plane\"][\"ax\"].legend()\n",
    "\n",
    "        # Set aspect ratio\n",
    "        self.plt[\"plane\"][\"ax\"].set_aspect(1/1.68)\n",
    "\n",
    "        # invert y\n",
    "        #self.plt[\"plane\"][\"ax\"].invert_yaxis()\n",
    "\n",
    "\n",
    "    def api_call(self, prm):\n",
    "        code = textwrap.dedent(\n",
    "f\"\"\"# import the Detection class\n",
    "from dorna_vision import Detection\n",
    "\n",
    "# detection parameters\n",
    "prm = {prm}\n",
    "\n",
    "# create the Detection object\n",
    "detection = Detection(camera=camera, robot=robot, **prm)\n",
    "\n",
    "# call the detection\n",
    "retval = detection.run()\"\"\")\n",
    "        return code\n",
    "    \n",
    "\n",
    "    def _detect_pattern(self, **kwargs):\n",
    "        try:\n",
    "            # adjust kwargs\n",
    "            prm = {}\n",
    "            _prm ={}\n",
    "            # feed\n",
    "            prm[\"feed\"] = self.widget_tr[\"source_feed\"].value\n",
    "            \n",
    "            # intensity\n",
    "            prm[\"intensity\"] = {\"a\": 1.0, \"b\": 0}\n",
    "            if kwargs[\"intensity_enb\"]:\n",
    "                prm[\"intensity\"] = {\"a\": kwargs[\"intensity_a\"], \"b\": kwargs[\"intensity_b\"]}\n",
    "                _prm[\"intensity\"] = prm[\"intensity\"]\n",
    "            \n",
    "            # color\n",
    "            prm[\"color\"] = {\"low_hsv\": [0, 0, 0], \"high_hsv\": [255, 255, 255], \"inv\": 0}\n",
    "            if kwargs[\"color_enb\"]:\n",
    "                prm[\"color\"] = {\"low_hsv\": [kwargs[k][0] for k in [\"color_h\", \"color_s\", \"color_v\"]], \"high_hsv\": [kwargs[k][1] for k in [\"color_h\", \"color_s\", \"color_v\"]], \"inv\": kwargs[\"color_inv\"]}\n",
    "                _prm[\"color\"] = prm[\"color\"]\n",
    "\n",
    "            # roi\n",
    "            prm[\"roi\"] = {\"corners\": [], \"inv\": 0, \"crop\": 0}\n",
    "            if kwargs[\"roi_enb\"]:\n",
    "                prm[\"roi\"] = {\"corners\": ast.literal_eval(kwargs[\"roi_value\"]), \"inv\": kwargs[\"roi_inv\"], \"crop\": kwargs[\"roi_crop\"]}\n",
    "                _prm[\"roi\"] = prm[\"roi\"]\n",
    "            \n",
    "            # detection\n",
    "            prm[\"detection\"] = {\"cmd\":None} \n",
    "            if kwargs[\"method_value\"] == 1:\n",
    "                prm[\"detection\"] = {\"cmd\":\"elp\", \"min_path_length\": kwargs[\"m_elp_min_path_length\"], \"min_line_length\": kwargs[\"m_elp_min_line_length\"], \"nfa_validation\": kwargs[\"m_elp_nfa_validation\"], \"sigma\": kwargs[\"m_elp_sigma\"], \"gradient_threshold_value\": kwargs[\"m_elp_gradient_threshold_value\"], \"pf_mode\": kwargs[\"m_elp_pf_mode\"]}\n",
    "                _prm[\"detection\"] = prm[\"detection\"]\n",
    "            elif kwargs[\"method_value\"] == 2:\n",
    "                prm[\"detection\"] = {\"cmd\":\"poly\", \"type\": kwargs[\"m_poly_type\"], \"inv\": kwargs[\"m_poly_inv\"], \"blur\": kwargs[\"m_poly_blur\"], \"thr\": kwargs[\"m_poly_thr\"], \"mean_sub\": kwargs[\"m_poly_mean_sub\"], \"side\": kwargs[\"m_poly_side\"]}\n",
    "                _prm[\"detection\"] = prm[\"detection\"]\n",
    "            elif kwargs[\"method_value\"] == 3:\n",
    "                prm[\"detection\"] = {\"cmd\":\"cnt\", \"type\": kwargs[\"m_cnt_type\"], \"inv\": kwargs[\"m_cnt_inv\"], \"blur\": kwargs[\"m_cnt_blur\"], \"thr\": kwargs[\"m_cnt_thr\"], \"mean_sub\": kwargs[\"m_cnt_mean_sub\"]}\n",
    "                _prm[\"detection\"] = prm[\"detection\"]\n",
    "            elif kwargs[\"method_value\"] == 4:\n",
    "                prm[\"detection\"] = {\"cmd\":\"aruco\", \"dictionary\": kwargs[\"m_aruco_dictionary\"], \"marker_length\": kwargs[\"m_aruco_marker_length\"], \"refine\": kwargs[\"m_aruco_refine\"] , \"subpix\": kwargs[\"m_aruco_subpix\"]}\n",
    "                _prm[\"detection\"] = prm[\"detection\"]\n",
    "            elif kwargs[\"method_value\"] == 5:\n",
    "                prm[\"detection\"] = {\"cmd\":\"ocr\", \"conf\": kwargs[\"m_ocr_conf\"]}\n",
    "                _prm[\"detection\"] = prm[\"detection\"]\n",
    "            elif kwargs[\"method_value\"] == 6:\n",
    "                cls_name =  [item.strip() for item in kwargs[\"m_od_cls\"].split(',') if item.strip()]\n",
    "                prm[\"detection\"] = {\"cmd\":\"od\", \"path\": self.widget_init[\"ml_detection_path\"].value, \"conf\": kwargs[\"m_od_conf\"], \"cls\": cls_name}   \n",
    "                _prm[\"detection\"] = prm[\"detection\"]\n",
    "            elif kwargs[\"method_value\"] == 7:\n",
    "                prm[\"detection\"] = {\"cmd\":\"cls\", \"path\": self.widget_init[\"ml_detection_path\"].value, \"conf\": kwargs[\"m_cls_conf\"]}   \n",
    "                _prm[\"detection\"] = prm[\"detection\"]\n",
    "\n",
    "            #limit\n",
    "            prm[\"limit\"] = {\"area\":[], \"aspect_ratio\":[], \"xyz\":[], \"inv\":0}\n",
    "            if kwargs[\"2d_range_enb\"]:\n",
    "                prm[\"limit\"][\"aspect_ratio\"] = list(kwargs[\"2d_range_aspect_ratio\"])\n",
    "                prm[\"limit\"][\"area\"] = list(kwargs[\"2d_range_area_range\"])\n",
    "                _prm[\"limit\"] = prm[\"limit\"]\n",
    "            if kwargs[\"3d_range_enb\"]:\n",
    "                prm[\"limit\"][\"xyz\"] = [list(kwargs[\"3d_range_x\"]), list(kwargs[\"3d_range_y\"]),list( kwargs[\"3d_range_z\"])]\n",
    "                if kwargs[\"3d_range_inv\"]:\n",
    "                    prm[\"limit\"][\"inv\"] = 1\n",
    "                _prm[\"limit\"] = prm[\"limit\"]\n",
    "            \n",
    "            # plane\n",
    "            prm[\"plane\"] = []\n",
    "            if kwargs[\"plane_enb\"]:\n",
    "                prm[\"plane\"] = ast.literal_eval(kwargs[\"plane_value\"])\n",
    "                _prm[\"plane\"] = prm[\"plane\"]\n",
    "            \n",
    "            # output\n",
    "            prm[\"output\"] = {\"max_det\": 1, \"shuffle\": 1, \"save_img\": 0, \"save_img_roi\": 0}\n",
    "            if kwargs[\"output_enb\"]:\n",
    "                prm[\"output\"] = { \"max_det\": kwargs[\"output_max_det\"], \"shuffle\": kwargs[\"output_shuffle\"], \"save_img\": kwargs[\"output_save\"], \"save_img_roi\": kwargs[\"output_save_roi\"]}\n",
    "                _prm[\"output\"] = prm[\"output\"]\n",
    "\n",
    "            \"\"\"hide and show inputs\"\"\"\n",
    "            show_key = [[key for key in self.widget_in.keys() if key.startswith(term)] for term in [\"m_nothing\", \"m_elp\", \"m_poly\", \"m_cnt\", \"m_aruco\", \"m_ocr\", \"m_od\", \"m_cls\"]][kwargs[\"method_value\"]]\n",
    "            hide_key = [key for key in self.widget_in.keys() if key.startswith('m_') and key not in show_key] \n",
    "            for k in show_key:\n",
    "                if self.widget_in[k].layout.display != \"flex\":\n",
    "                    self.widget_in[k].layout.display = \"flex\"\n",
    "            for k in hide_key:\n",
    "                if self.widget_in[k].layout.display != \"none\":\n",
    "                    self.widget_in[k].layout.display = \"none\"\n",
    "            self.hide_key = hide_key\n",
    "            self.show_key = show_key\n",
    "\n",
    "            # run pattern detection\n",
    "            self.prm = prm\n",
    "            retval = self.d.run(data=self.data, **prm)\n",
    "            self.data = dict(self.d.camera_data)\n",
    "            \n",
    "            # adjust the frame size\n",
    "            self.plt[\"out\"][\"img\"].set_extent([0, self.d.camera_data[prm[\"feed\"]].shape[1], self.d.camera_data[prm[\"feed\"]].shape[0], 0])\n",
    "            self.plt[\"method\"][\"img\"].set_extent([0, self.d.camera_data[prm[\"feed\"]].shape[1], self.d.camera_data[prm[\"feed\"]].shape[0], 0])\n",
    "\n",
    "            # display thr\n",
    "            if kwargs[\"method_value\"] in [2, 3]: # polygon and contour\n",
    "                #self.method_plt.clear_output(wait=True)\n",
    "                #self.plt[\"method\"][\"img\"].set_visible(True)\n",
    "                self.plt[\"method\"][\"img\"].set_data(cv.cvtColor(self.d.img_thr, cv.COLOR_GRAY2RGB))\n",
    "                self.plt[\"method\"][\"fig\"].canvas.draw_idle()\n",
    "                self.plt_method.layout.visibility = \"visible\"\n",
    "\n",
    "            else:      \n",
    "                #self.plt[\"method\"][\"img\"].set_visible(False)\n",
    "                #self.plt_method.layout.display = \"none\"\n",
    "                self.plt_method.layout.visibility = \"hidden\"\n",
    "\n",
    "            # Update the existing plot\n",
    "            self.plt[\"out\"][\"img\"].set_data(cv.cvtColor(self.d.img, cv.COLOR_BGR2RGB))\n",
    "            self.plt[\"out\"][\"fig\"].canvas.draw_idle() \n",
    "            \n",
    "            # type retval\n",
    "            self.retval = retval\n",
    "            json_str = json.dumps(retval)\n",
    "            converted_retval = json.loads(json_str, parse_int=lambda x: int(x), parse_float=lambda x: float(x), parse_constant=lambda x: x, object_hook=lambda d: {k: 1 if v is True else 0 if v is False else v for k, v in d.items()}) \n",
    "            self.widget_tr[\"out_return\"].value = json.dumps(converted_retval)\n",
    "\n",
    "            # api call\n",
    "            self.widget_tr[\"out_prm\"].value = self.api_call(_prm)\n",
    "            self.config = kwargs\n",
    "            \n",
    "        except Exception as ex:\n",
    "            print(ex)\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e2103d9a5a84eefa52e4cc5098758c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Button(button_style='success', description='Capture Image', disabled=True, style"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = Detection_app()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 2.75180840e+02,  4.77229962e+01, -2.46235103e-01,\n",
       "          1.00000000e+00]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dorna2 import Dorna\n",
    "robot = Dorna()\n",
    "c= np.array([-29.8394076526165, 46.82409390807152, 85.29999554157257, 1])\n",
    "r = np.array([275.185671, 47.727749, 47.801157, 1])\n",
    "[275.32813519763033, 47.97720313547765, -0.6088915424005847]\n",
    "t = np.matrix([[ 3.26187665e-03, -9.99994251e-01,  9.04813990e-04,\n",
    "          0.74+4.62883822e+01],\n",
    "        [ 9.99989095e-01,  3.26495383e-03, -3.34498454e-03,\n",
    "          -0.93+3.09087023e+01],\n",
    "        [ 3.34201673e-03, -9.15715051e-04,  9.99993996e-01,\n",
    "         -2.19488233e+00],\n",
    "        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
    "          1.00000000e+00]])\n",
    "joint = [0.109863, 7.44873, -101.733398, -0.021973, 4.262695, 0.109863]\n",
    "T_camholder_to_base = robot.kinematic.Ti_r_world(i=5, joint=joint[0:6])\n",
    "T_cam_to_camholder = np.matrix(t)\n",
    "T_cam_to_base = np.matmul(T_camholder_to_base, T_cam_to_camholder)\n",
    "frame_mat_inv = T_cam_to_base\n",
    "\n",
    "\n",
    "np.matmul(frame_mat_inv, c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.00525873615, -0.999894519, 0.0134620306, 46.5174596],\n",
       " [0.999959617, 0.00535678348, -0.0073579648, 32.0776662],\n",
       " [0.00728773209, -0.0135001806, 0.99988231, -4.24772615],\n",
       " [0.0, 0.0, 0.0, 1.0]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[ 5.25873615e-03, -9.99894519e-01,  1.34620306e-02,\n",
    "        4.65174596e+01],\n",
    "      [ 9.99959617e-01,  5.35678348e-03, -7.35796480e-03,\n",
    "        3.20776662e+01],\n",
    "      [ 7.28773209e-03, -1.35001806e-02,  9.99882310e-01,\n",
    "       -4.24772615e+00],\n",
    "      [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
    "        1.00000000e+00]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define your input points and their corresponding targets\n",
    "train_points = np.array([\n",
    "    [0.0, 0.0, 0.0],\n",
    "    [1.0, 0.0, 0.0],\n",
    "    [0.0, 1.0, 0.0],\n",
    "    [0.0, 0.0, 1.0]\n",
    "])\n",
    "\n",
    "train_targets = np.array([\n",
    "    [0.0, 0.0, 0.0],\n",
    "    [8.0, 0.0, 0.0],\n",
    "    [0.0, 8.0, 0.0],\n",
    "    [0.0, 1.0, 8.0]\n",
    "])\n",
    "\n",
    "# Append a column of ones to the input points to account for translation\n",
    "train_points_augmented = np.hstack((train_points, np.ones((train_points.shape[0], 1))))\n",
    "\n",
    "# Solve for the affine transformation matrix\n",
    "# X * T = Y => T = (X.T * X)^-1 * X.T * Y\n",
    "T, _, _, _ = np.linalg.lstsq(train_points_augmented, train_targets, rcond=None)\n",
    "\n",
    "# Define a function to apply the transformation to new points\n",
    "def map_point(point, T):\n",
    "    point_augmented = np.append(point, 1)  # Add the homogeneous coordinate\n",
    "    mapped_point = np.dot(point_augmented, T)\n",
    "    return mapped_point\n",
    "\n",
    "# Test the transformation on a new point\n",
    "test_point = np.array([0.0, 0.0, 1.1])\n",
    "predicted_xyz = map_point(test_point, T)\n",
    "\n",
    "print(\"Predicted XYZ coordinates for test point:\", predicted_xyz)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define input points and corresponding targets\n",
    "train_points = np.array([\n",
    "    [0.0, 0.0, 0.0],\n",
    "    [1.0, 0.0, 0.0],\n",
    "    [0.0, 1.0, 0.0],\n",
    "    [0.0, 0.0, 1.0]\n",
    "])\n",
    "\n",
    "train_targets = np.array([\n",
    "    [0.0, 0.0, 0.0],\n",
    "    [8.0, 0.0, 0.0],\n",
    "    [0.0, 8.0, 0.0],\n",
    "    [0.0, 1.0, 8.0]\n",
    "])\n",
    "\n",
    "# Test point for weighting\n",
    "test_point = np.array([1.5, 2.5, 1])\n",
    "\n",
    "# Function to compute weights based on distance\n",
    "def compute_weights(test_point, train_points, p=10):\n",
    "    distances = np.linalg.norm(train_points - test_point, axis=1)\n",
    "    weights = 1 / (distances**p + 1e-6)  # Avoid division by zero\n",
    "    return weights\n",
    "\n",
    "# Compute weights using the specified power p\n",
    "weights = compute_weights(test_point, train_points, p=10)  # Use p=2 or any value for p\n",
    "\n",
    "# Create diagonal weight matrix\n",
    "W = np.diag(weights)\n",
    "\n",
    "# Augment training points\n",
    "train_points_augmented = np.hstack((train_points, np.ones((train_points.shape[0], 1))))\n",
    "\n",
    "# Apply weights to the training data\n",
    "weighted_train_points = W @ train_points_augmented\n",
    "weighted_train_targets = W @ train_targets\n",
    "\n",
    "# Solve for the affine transformation matrix with weights\n",
    "T, _, _, _ = np.linalg.lstsq(weighted_train_points, weighted_train_targets, rcond=None)\n",
    "\n",
    "# Define a function to apply the transformation\n",
    "def map_point(point, T):\n",
    "    point_augmented = np.append(point, 1)\n",
    "    return np.dot(point_augmented, T)\n",
    "\n",
    "# Predict the target for the test point\n",
    "predicted_xyz = map_point(test_point, T)\n",
    "\n",
    "print(\"Predicted XYZ coordinates for test point:\", predicted_xyz)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the Detection class\n",
    "from dorna_vision import Detection\n",
    "from dorna2 import Dorna\n",
    "from camera import Camera\n",
    "camera = Camera()\n",
    "camera.connect()\n",
    "\n",
    "robot = Dorna()\n",
    "robot.connect(\"192.168.254.87\")\n",
    "# detection parameters\n",
    "prm = {'detection': {'cmd': 'elp', 'min_path_length': 360, 'min_line_length': 116, 'nfa_validation': True, 'sigma': 2, 'gradient_threshold_value': 12, 'pf_mode': False}, 'limit': {'area': [0, 100000], 'aspect_ratio': [0.88, 0.95], 'xyz': [], 'inv': 0}, 'plane': [[-0.3, -0.21], [0.31, -0.45], [0.06, 0.8]]}\n",
    "\n",
    "# create the Detection object\n",
    "detection = Detection(camera=camera, robot=robot, **prm)\n",
    "\n",
    "# call the detection\n",
    "retval = detection.run()\n",
    "print(retval)\n",
    "\n",
    "robot.close()    \n",
    "camera.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
